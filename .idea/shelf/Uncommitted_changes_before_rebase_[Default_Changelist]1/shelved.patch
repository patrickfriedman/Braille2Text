Index: app/venv/Lib/site-packages/imutils/object_detection.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/venv/Lib/site-packages/imutils/object_detection.py	(date 1605210046491)
+++ app/venv/Lib/site-packages/imutils/object_detection.py	(date 1605210046491)
@@ -0,0 +1,65 @@
+# import the necessary packages
+import numpy as np
+
+def non_max_suppression(boxes, probs=None, overlapThresh=0.3):
+	# if there are no boxes, return an empty list
+	if len(boxes) == 0:
+		return []
+
+	# if the bounding boxes are integers, convert them to floats -- this
+	# is important since we'll be doing a bunch of divisions
+	if boxes.dtype.kind == "i":
+		boxes = boxes.astype("float")
+
+	# initialize the list of picked indexes
+	pick = []
+
+	# grab the coordinates of the bounding boxes
+	x1 = boxes[:, 0]
+	y1 = boxes[:, 1]
+	x2 = boxes[:, 2]
+	y2 = boxes[:, 3]
+
+	# compute the area of the bounding boxes and grab the indexes to sort
+	# (in the case that no probabilities are provided, simply sort on the
+	# bottom-left y-coordinate)
+	area = (x2 - x1 + 1) * (y2 - y1 + 1)
+	idxs = y2
+
+	# if probabilities are provided, sort on them instead
+	if probs is not None:
+		idxs = probs
+
+	# sort the indexes
+	idxs = np.argsort(idxs)
+
+	# keep looping while some indexes still remain in the indexes list
+	while len(idxs) > 0:
+		# grab the last index in the indexes list and add the index value
+		# to the list of picked indexes
+		last = len(idxs) - 1
+		i = idxs[last]
+		pick.append(i)
+
+		# find the largest (x, y) coordinates for the start of the bounding
+		# box and the smallest (x, y) coordinates for the end of the bounding
+		# box
+		xx1 = np.maximum(x1[i], x1[idxs[:last]])
+		yy1 = np.maximum(y1[i], y1[idxs[:last]])
+		xx2 = np.minimum(x2[i], x2[idxs[:last]])
+		yy2 = np.minimum(y2[i], y2[idxs[:last]])
+
+		# compute the width and height of the bounding box
+		w = np.maximum(0, xx2 - xx1 + 1)
+		h = np.maximum(0, yy2 - yy1 + 1)
+
+		# compute the ratio of overlap
+		overlap = (w * h) / area[idxs[:last]]
+
+		# delete all indexes from the index list that have overlap greater
+		# than the provided overlap threshold
+		idxs = np.delete(idxs, np.concatenate(([last],
+			np.where(overlap > overlapThresh)[0])))
+
+	# return only the bounding boxes that were picked
+	return boxes[pick].astype("int")
\ No newline at end of file
Index: app/venv/Lib/site-packages/imutils/paths.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/venv/Lib/site-packages/imutils/paths.py	(date 1605210046484)
+++ app/venv/Lib/site-packages/imutils/paths.py	(date 1605210046484)
@@ -0,0 +1,29 @@
+# import the necessary packages
+import os
+
+image_types = (".jpg", ".jpeg", ".png", ".bmp", ".tif", ".tiff")
+
+
+def list_images(basePath, contains=None):
+    # return the set of files that are valid
+    return list_files(basePath, validExts=image_types, contains=contains)
+
+
+def list_files(basePath, validExts=None, contains=None):
+    # loop over the directory structure
+    for (rootDir, dirNames, filenames) in os.walk(basePath):
+        # loop over the filenames in the current directory
+        for filename in filenames:
+            # if the contains string is not none and the filename does not contain
+            # the supplied string, then ignore the file
+            if contains is not None and filename.find(contains) == -1:
+                continue
+
+            # determine the file extension of the current file
+            ext = filename[filename.rfind("."):].lower()
+
+            # check to see if the file is an image and should be processed
+            if validExts is None or ext.endswith(validExts):
+                # construct the path to the image and yield it
+                imagePath = os.path.join(rootDir, filename)
+                yield imagePath
Index: app/venv/Lib/site-packages/imutils/perspective.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/venv/Lib/site-packages/imutils/perspective.py	(date 1605210046510)
+++ app/venv/Lib/site-packages/imutils/perspective.py	(date 1605210046510)
@@ -0,0 +1,72 @@
+# author:    Adrian Rosebrock
+# website:   http://www.pyimagesearch.com
+
+# import the necessary packages
+from scipy.spatial import distance as dist
+import numpy as np
+import cv2
+
+def order_points(pts):
+    # sort the points based on their x-coordinates
+    xSorted = pts[np.argsort(pts[:, 0]), :]
+
+    # grab the left-most and right-most points from the sorted
+    # x-roodinate points
+    leftMost = xSorted[:2, :]
+    rightMost = xSorted[2:, :]
+
+    # now, sort the left-most coordinates according to their
+    # y-coordinates so we can grab the top-left and bottom-left
+    # points, respectively
+    leftMost = leftMost[np.argsort(leftMost[:, 1]), :]
+    (tl, bl) = leftMost
+
+    # now that we have the top-left coordinate, use it as an
+    # anchor to calculate the Euclidean distance between the
+    # top-left and right-most points; by the Pythagorean
+    # theorem, the point with the largest distance will be
+    # our bottom-right point
+    D = dist.cdist(tl[np.newaxis], rightMost, "euclidean")[0]
+    (br, tr) = rightMost[np.argsort(D)[::-1], :]
+
+    # return the coordinates in top-left, top-right,
+    # bottom-right, and bottom-left order
+    return np.array([tl, tr, br, bl], dtype="float32")
+
+def four_point_transform(image, pts):
+    # obtain a consistent order of the points and unpack them
+    # individually
+    rect = order_points(pts)
+    (tl, tr, br, bl) = rect
+
+    # compute the width of the new image, which will be the
+    # maximum distance between bottom-right and bottom-left
+    # x-coordiates or the top-right and top-left x-coordinates
+    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))
+    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))
+    maxWidth = max(int(widthA), int(widthB))
+
+    # compute the height of the new image, which will be the
+    # maximum distance between the top-right and bottom-right
+    # y-coordinates or the top-left and bottom-left y-coordinates
+    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))
+    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))
+    maxHeight = max(int(heightA), int(heightB))
+
+    # now that we have the dimensions of the new image, construct
+    # the set of destination points to obtain a "birds eye view",
+    # (i.e. top-down view) of the image, again specifying points
+    # in the top-left, top-right, bottom-right, and bottom-left
+    # order
+    dst = np.array([
+        [0, 0],
+        [maxWidth - 1, 0],
+        [maxWidth - 1, maxHeight - 1],
+        [0, maxHeight - 1]], dtype="float32")
+
+    # compute the perspective transform matrix and then apply it
+    M = cv2.getPerspectiveTransform(rect, dst)
+    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))
+
+    # return the warped image
+    return warped
\ No newline at end of file
Index: app/venv/Lib/site-packages/imutils/text.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/venv/Lib/site-packages/imutils/text.py	(date 1605210046501)
+++ app/venv/Lib/site-packages/imutils/text.py	(date 1605210046501)
@@ -0,0 +1,107 @@
+import cv2
+
+
+def put_text(img, text, org, font_face, font_scale, color, thickness=1, line_type=8, bottom_left_origin=False):
+    """Utility for drawing text with line breaks
+
+    :param img: Image.
+    :param text: Text string to be drawn.
+    :param org: Bottom-left corner of the first line of the text string in the image.
+    :param font_face: Font type. One of FONT_HERSHEY_SIMPLEX, FONT_HERSHEY_PLAIN, FONT_HERSHEY_DUPLEX,
+                          FONT_HERSHEY_COMPLEX, FONT_HERSHEY_TRIPLEX, FONT_HERSHEY_COMPLEX_SMALL,
+                          FONT_HERSHEY_SCRIPT_SIMPLEX, or FONT_HERSHEY_SCRIPT_COMPLEX, where each of the font ID’s
+                          can be combined with FONT_ITALIC to get the slanted letters.
+    :param font_scale: Font scale factor that is multiplied by the font-specific base size.
+    :param color: Text color.
+    :param thickness: Thickness of the lines used to draw a text.
+    :param line_type: Line type. See the line for details.
+    :param bottom_left_origin: When true, the image data origin is at the bottom-left corner.
+                               Otherwise, it is at the top-left corner.
+    :return: None; image is modified in place
+    """
+    # Break out drawing coords
+    x, y = org
+
+    # Break text into list of text lines
+    text_lines = text.split('\n')
+
+    # Get height of text lines in pixels (height of all lines is the same)
+    _, line_height = cv2.getTextSize('', font_face, font_scale, thickness)[0]
+    # Set distance between lines in pixels
+    line_gap = line_height // 3
+
+    for i, text_line in enumerate(text_lines):
+        # Find total size of text block before this line
+        line_y_adjustment = i * (line_gap + line_height)
+
+        # Move text down from original line based on line number
+        if not bottom_left_origin:
+            line_y = y + line_y_adjustment
+        else:
+            line_y = y - line_y_adjustment
+
+        # Draw text
+        cv2.putText(img,
+                    text=text_lines[i],
+                    org=(x, line_y),
+                    fontFace=font_face,
+                    fontScale=font_scale,
+                    color=color,
+                    thickness=thickness,
+                    lineType=line_type,
+                    bottomLeftOrigin=bottom_left_origin)
+
+
+def put_centered_text(img, text, font_face, font_scale, color, thickness=1, line_type=8):
+    """Utility for drawing vertically & horizontally centered text with line breaks
+
+    :param img: Image.
+    :param text: Text string to be drawn.
+    :param font_face: Font type. One of FONT_HERSHEY_SIMPLEX, FONT_HERSHEY_PLAIN, FONT_HERSHEY_DUPLEX,
+                          FONT_HERSHEY_COMPLEX, FONT_HERSHEY_TRIPLEX, FONT_HERSHEY_COMPLEX_SMALL,
+                          FONT_HERSHEY_SCRIPT_SIMPLEX, or FONT_HERSHEY_SCRIPT_COMPLEX, where each of the font ID’s
+                          can be combined with FONT_ITALIC to get the slanted letters.
+    :param font_scale: Font scale factor that is multiplied by the font-specific base size.
+    :param color: Text color.
+    :param thickness: Thickness of the lines used to draw a text.
+    :param line_type: Line type. See the line for details.
+    :return: None; image is modified in place
+    """
+    # Save img dimensions
+    img_h, img_w = img.shape[:2]
+
+    # Break text into list of text lines
+    text_lines = text.split('\n')
+
+    # Get height of text lines in pixels (height of all lines is the same; width differs)
+    _, line_height = cv2.getTextSize('', font_face, font_scale, thickness)[0]
+    # Set distance between lines in pixels
+    line_gap = line_height // 3
+
+    # Calculate total text block height for centering
+    text_block_height = len(text_lines) * (line_height + line_gap)
+    text_block_height -= line_gap  # There's one less gap than lines
+
+    for i, text_line in enumerate(text_lines):
+        # Get width of text line in pixels (height of all lines is the same)
+        line_width, _ = cv2.getTextSize(text_line, font_face, font_scale, thickness)[0]
+
+        # Center line with image dimensions
+        x = (img_w - line_width) // 2
+        y = (img_h + line_height) // 2
+
+        # Find total size of text block before this line
+        line_adjustment = i * (line_gap + line_height)
+
+        # Adjust line y and re-center relative to total text block height
+        y += line_adjustment - text_block_height // 2 + line_gap
+
+        # Draw text
+        cv2.putText(img,
+                    text=text_lines[i],
+                    org=(x, y),
+                    fontFace=font_face,
+                    fontScale=font_scale,
+                    color=color,
+                    thickness=thickness,
+                    lineType=line_type)
Index: app/venv/Lib/site-packages/imutils/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/venv/Lib/site-packages/imutils/__init__.py	(date 1605210046517)
+++ app/venv/Lib/site-packages/imutils/__init__.py	(date 1605210046517)
@@ -0,0 +1,23 @@
+# author:	Adrian Rosebrock
+# website:	http://www.pyimagesearch.com
+
+# set the version number
+__version__ = "0.5.3"
+
+# import the necessary packages
+from .convenience import translate
+from .convenience import rotate
+from .convenience import rotate_bound
+from .convenience import resize
+from .convenience import skeletonize
+from .convenience import opencv2matplotlib
+from .convenience import url_to_image
+from .convenience import auto_canny
+from .convenience import grab_contours
+from .convenience import is_cv2
+from .convenience import is_cv3
+from .convenience import is_cv4
+from .convenience import check_opencv_version
+from .convenience import build_montages
+from .convenience import adjust_brightness_contrast
+from .meta import find_function
Index: app/venv/Lib/site-packages/imutils/io/tempfile.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/venv/Lib/site-packages/imutils/io/tempfile.py	(date 1605210046536)
+++ app/venv/Lib/site-packages/imutils/io/tempfile.py	(date 1605210046536)
@@ -0,0 +1,13 @@
+# import the necessary packages
+import uuid
+import os
+
+class TempFile:
+	def __init__(self, basePath="./", ext=".jpg"):
+		# construct the file path
+		self.path = "{base_path}/{rand}{ext}".format(base_path=basePath, rand=str(uuid.uuid4()),
+			ext=ext)
+
+	def cleanup(self):
+		# remove the file
+		os.remove(self.path)
\ No newline at end of file
Index: app/venv/Lib/site-packages/imutils/io/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/venv/Lib/site-packages/imutils/io/__init__.py	(date 1605210046525)
+++ app/venv/Lib/site-packages/imutils/io/__init__.py	(date 1605210046525)
@@ -0,0 +1,2 @@
+# import the necessary packages
+from .tempfile import TempFile
\ No newline at end of file
Index: app/venv/Lib/site-packages/imutils/video/filevideostream.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/venv/Lib/site-packages/imutils/video/filevideostream.py	(date 1605210046544)
+++ app/venv/Lib/site-packages/imutils/video/filevideostream.py	(date 1605210046544)
@@ -0,0 +1,99 @@
+# import the necessary packages
+from threading import Thread
+import sys
+import cv2
+import time
+
+# import the Queue class from Python 3
+if sys.version_info >= (3, 0):
+	from queue import Queue
+
+# otherwise, import the Queue class for Python 2.7
+else:
+	from Queue import Queue
+
+
+class FileVideoStream:
+	def __init__(self, path, transform=None, queue_size=128):
+		# initialize the file video stream along with the boolean
+		# used to indicate if the thread should be stopped or not
+		self.stream = cv2.VideoCapture(path)
+		self.stopped = False
+		self.transform = transform
+
+		# initialize the queue used to store frames read from
+		# the video file
+		self.Q = Queue(maxsize=queue_size)
+		# intialize thread
+		self.thread = Thread(target=self.update, args=())
+		self.thread.daemon = True
+
+	def start(self):
+		# start a thread to read frames from the file video stream
+		self.thread.start()
+		return self
+
+	def update(self):
+		# keep looping infinitely
+		while True:
+			# if the thread indicator variable is set, stop the
+			# thread
+			if self.stopped:
+				break
+
+			# otherwise, ensure the queue has room in it
+			if not self.Q.full():
+				# read the next frame from the file
+				(grabbed, frame) = self.stream.read()
+
+				# if the `grabbed` boolean is `False`, then we have
+				# reached the end of the video file
+				if not grabbed:
+					self.stopped = True
+					
+				# if there are transforms to be done, might as well
+				# do them on producer thread before handing back to
+				# consumer thread. ie. Usually the producer is so far
+				# ahead of consumer that we have time to spare.
+				#
+				# Python is not parallel but the transform operations
+				# are usually OpenCV native so release the GIL.
+				#
+				# Really just trying to avoid spinning up additional
+				# native threads and overheads of additional
+				# producer/consumer queues since this one was generally
+				# idle grabbing frames.
+				if self.transform:
+					frame = self.transform(frame)
+
+				# add the frame to the queue
+				self.Q.put(frame)
+			else:
+				time.sleep(0.1)  # Rest for 10ms, we have a full queue
+
+		self.stream.release()
+
+	def read(self):
+		# return next frame in the queue
+		return self.Q.get()
+
+	# Insufficient to have consumer use while(more()) which does
+	# not take into account if the producer has reached end of
+	# file stream.
+	def running(self):
+		return self.more() or not self.stopped
+
+	def more(self):
+		# return True if there are still frames in the queue. If stream is not stopped, try to wait a moment
+		tries = 0
+		while self.Q.qsize() == 0 and not self.stopped and tries < 5:
+			time.sleep(0.1)
+			tries += 1
+
+		return self.Q.qsize() > 0
+
+	def stop(self):
+		# indicate that the thread should be stopped
+		self.stopped = True
+		# wait until stream resources are released (producer thread might be still grabbing frame)
+		self.thread.join()
Index: app/venv/Lib/site-packages/imutils/video/pivideostream.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/venv/Lib/site-packages/imutils/video/pivideostream.py	(date 1605210046558)
+++ app/venv/Lib/site-packages/imutils/video/pivideostream.py	(date 1605210046558)
@@ -0,0 +1,59 @@
+# import the necessary packages
+from picamera.array import PiRGBArray
+from picamera import PiCamera
+from threading import Thread
+import cv2
+
+class PiVideoStream:
+	def __init__(self, resolution=(320, 240), framerate=32, **kwargs):
+		# initialize the camera
+		self.camera = PiCamera()
+
+		# set camera parameters
+		self.camera.resolution = resolution
+		self.camera.framerate = framerate
+
+		# set optional camera parameters (refer to PiCamera docs)
+		for (arg, value) in kwargs.items():
+			setattr(self.camera, arg, value)
+
+		# initialize the stream
+		self.rawCapture = PiRGBArray(self.camera, size=resolution)
+		self.stream = self.camera.capture_continuous(self.rawCapture,
+			format="bgr", use_video_port=True)
+
+		# initialize the frame and the variable used to indicate
+		# if the thread should be stopped
+		self.frame = None
+		self.stopped = False
+
+	def start(self):
+		# start the thread to read frames from the video stream
+		t = Thread(target=self.update, args=())
+		t.daemon = True
+		t.start()
+		return self
+
+	def update(self):
+		# keep looping infinitely until the thread is stopped
+		for f in self.stream:
+			# grab the frame from the stream and clear the stream in
+			# preparation for the next frame
+			self.frame = f.array
+			self.rawCapture.truncate(0)
+
+			# if the thread indicator variable is set, stop the thread
+			# and resource camera resources
+			if self.stopped:
+				self.stream.close()
+				self.rawCapture.close()
+				self.camera.close()
+				return
+
+	def read(self):
+		# return the frame most recently read
+		return self.frame
+
+	def stop(self):
+		# indicate that the thread should be stopped
+		self.stopped = True
Index: app/venv/Lib/site-packages/imutils/video/count_frames.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/venv/Lib/site-packages/imutils/video/count_frames.py	(date 1605210046552)
+++ app/venv/Lib/site-packages/imutils/video/count_frames.py	(date 1605210046552)
@@ -0,0 +1,60 @@
+# import the necessary packages
+from ..convenience import is_cv3
+import cv2
+
+def count_frames(path, override=False):
+	# grab a pointer to the video file and initialize the total
+	# number of frames read
+	video = cv2.VideoCapture(path)
+	total = 0
+
+	# if the override flag is passed in, revert to the manual
+	# method of counting frames
+	if override:
+		total = count_frames_manual(video)
+
+	# otherwise, let's try the fast way first
+	else:
+		# lets try to determine the number of frames in a video
+		# via video properties; this method can be very buggy
+		# and might throw an error based on your OpenCV version
+		# or may fail entirely based on your which video codecs
+		# you have installed
+		try:
+			# check if we are using OpenCV 3
+			if is_cv3():
+				total = int(video.get(cv2.CAP_PROP_FRAME_COUNT))
+
+			# otherwise, we are using OpenCV 2.4
+			else:
+				total = int(video.get(cv2.cv.CV_CAP_PROP_FRAME_COUNT))
+
+		# uh-oh, we got an error -- revert to counting manually
+		except:
+			total = count_frames_manual(video)
+
+	# release the video file pointer
+	video.release()
+
+	# return the total number of frames in the video
+	return total
+
+def count_frames_manual(video):
+	# initialize the total number of frames read
+	total = 0
+
+	# loop over the frames of the video
+	while True:
+		# grab the current frame
+		(grabbed, frame) = video.read()
+	 
+		# check to see if we have reached the end of the
+		# video
+		if not grabbed:
+			break
+
+		# increment the total number of frames read
+		total += 1
+
+	# return the total number of frames in the video file
+	return total
\ No newline at end of file
Index: app/venv/Lib/site-packages/imutils/video/webcamvideostream.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/venv/Lib/site-packages/imutils/video/webcamvideostream.py	(date 1605210046575)
+++ app/venv/Lib/site-packages/imutils/video/webcamvideostream.py	(date 1605210046575)
@@ -0,0 +1,42 @@
+# import the necessary packages
+from threading import Thread
+import cv2
+
+class WebcamVideoStream:
+	def __init__(self, src=0, name="WebcamVideoStream"):
+		# initialize the video camera stream and read the first frame
+		# from the stream
+		self.stream = cv2.VideoCapture(src)
+		(self.grabbed, self.frame) = self.stream.read()
+
+		# initialize the thread name
+		self.name = name
+
+		# initialize the variable used to indicate if the thread should
+		# be stopped
+		self.stopped = False
+
+	def start(self):
+		# start the thread to read frames from the video stream
+		t = Thread(target=self.update, name=self.name, args=())
+		t.daemon = True
+		t.start()
+		return self
+
+	def update(self):
+		# keep looping infinitely until the thread is stopped
+		while True:
+			# if the thread indicator variable is set, stop the thread
+			if self.stopped:
+				return
+
+			# otherwise, read the next frame from the stream
+			(self.grabbed, self.frame) = self.stream.read()
+
+	def read(self):
+		# return the frame most recently read
+		return self.frame
+
+	def stop(self):
+		# indicate that the thread should be stopped
+		self.stopped = True
Index: app/venv/Lib/site-packages/imutils/video/fps.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/venv/Lib/site-packages/imutils/video/fps.py	(date 1605210046568)
+++ app/venv/Lib/site-packages/imutils/video/fps.py	(date 1605210046568)
@@ -0,0 +1,33 @@
+# import the necessary packages
+import datetime
+
+class FPS:
+	def __init__(self):
+		# store the start time, end time, and total number of frames
+		# that were examined between the start and end intervals
+		self._start = None
+		self._end = None
+		self._numFrames = 0
+
+	def start(self):
+		# start the timer
+		self._start = datetime.datetime.now()
+		return self
+
+	def stop(self):
+		# stop the timer
+		self._end = datetime.datetime.now()
+
+	def update(self):
+		# increment the total number of frames examined during the
+		# start and end intervals
+		self._numFrames += 1
+
+	def elapsed(self):
+		# return the total number of seconds between the start and
+		# end interval
+		return (self._end - self._start).total_seconds()
+
+	def fps(self):
+		# compute the (approximate) frames per second
+		return self._numFrames / self.elapsed()
\ No newline at end of file
Index: app/venv/Lib/site-packages/imutils/video/videostream.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/venv/Lib/site-packages/imutils/video/videostream.py	(date 1605210046582)
+++ app/venv/Lib/site-packages/imutils/video/videostream.py	(date 1605210046582)
@@ -0,0 +1,39 @@
+# import the necessary packages
+from .webcamvideostream import WebcamVideoStream
+
+class VideoStream:
+	def __init__(self, src=0, usePiCamera=False, resolution=(320, 240),
+		framerate=32, **kwargs):
+		# check to see if the picamera module should be used
+		if usePiCamera:
+			# only import the picamera packages unless we are
+			# explicity told to do so -- this helps remove the
+			# requirement of `picamera[array]` from desktops or
+			# laptops that still want to use the `imutils` package
+			from .pivideostream import PiVideoStream
+
+			# initialize the picamera stream and allow the camera
+			# sensor to warmup
+			self.stream = PiVideoStream(resolution=resolution,
+				framerate=framerate, **kwargs)
+
+		# otherwise, we are using OpenCV so initialize the webcam
+		# stream
+		else:
+			self.stream = WebcamVideoStream(src=src)
+
+	def start(self):
+		# start the threaded video stream
+		return self.stream.start()
+
+	def update(self):
+		# grab the next frame from the stream
+		self.stream.update()
+
+	def read(self):
+		# return the current frame
+		return self.stream.read()
+
+	def stop(self):
+		# stop the thread and release any resources
+		self.stream.stop()
Index: app/venv/Lib/site-packages/imutils/video/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/venv/Lib/site-packages/imutils/video/__init__.py	(date 1605210046597)
+++ app/venv/Lib/site-packages/imutils/video/__init__.py	(date 1605210046597)
@@ -0,0 +1,6 @@
+# import the necessary packages
+from .count_frames import count_frames
+from .fps import FPS
+from .videostream import VideoStream
+from .webcamvideostream import WebcamVideoStream
+from .filevideostream import FileVideoStream
\ No newline at end of file
Index: app/venv/Lib/site-packages/imutils/feature/dense.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/venv/Lib/site-packages/imutils/feature/dense.py	(date 1605210046590)
+++ app/venv/Lib/site-packages/imutils/feature/dense.py	(date 1605210046590)
@@ -0,0 +1,24 @@
+import cv2
+
+class DENSE:
+    def __init__(self, step=6, radius=.5):
+        self.step = step
+        self.radius = radius
+
+    def detect(self, img):
+        # initialize our list of keypoints
+        kps = []
+
+        # loop over the height and with of the image, taking a `step`
+        # in each direction
+        for x in range(0, img.shape[1], self.step):
+            for y in range(0, img.shape[0], self.step):
+                # create a keypoint and add it to the keypoints list
+                kps.append(cv2.KeyPoint(x, y, self.radius))
+
+        # return the dense keypoints
+        return kps
+
+    def setInt(self, var, val):
+        if var == "initXyStep":
+            self.step = val
Index: app/venv/Lib/site-packages/imutils/feature/factories.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/venv/Lib/site-packages/imutils/feature/factories.py	(date 1605210046612)
+++ app/venv/Lib/site-packages/imutils/feature/factories.py	(date 1605210046612)
@@ -0,0 +1,123 @@
+from ..convenience import is_cv2
+import cv2
+from .dense import DENSE
+from .gftt import GFTT
+from .harris import HARRIS
+from .rootsift import RootSIFT
+
+if is_cv2():
+    def FeatureDetector_create(method):
+        method = method.upper()
+        if method == "DENSE":
+            return DENSE()
+        elif method == "GFTT":
+            return GFTT()
+        elif method == "HARRIS":
+            return HARRIS()
+        return cv2.FeatureDetector_create(method)
+
+    def DescriptorExtractor_create(method):
+        method = method.upper()
+        if method == "ROOTSIFT":
+            return RootSIFT()
+        return cv2.DescriptorExtractor_create(method)
+
+    def DescriptorMatcher_create(method):
+        return cv2.DescriptorMatcher_create(method)
+
+else:
+    try:
+        _DETECTOR_FACTORY = {"BRISK": cv2.BRISK_create,
+                             "DENSE": DENSE,
+                             "FAST": cv2.FastFeatureDetector_create,
+                             "GFTT": GFTT,
+                             "HARRIS": HARRIS,
+                             "MSER": cv2.MSER_create,
+                             "ORB": cv2.ORB_create,
+                             "SIFT": cv2.xfeatures2d.SIFT_create,
+                             "SURF": cv2.xfeatures2d.SURF_create,
+                             "STAR": cv2.xfeatures2d.StarDetector_create
+                             }
+
+        _EXTRACTOR_FACTORY = {"SIFT": cv2.xfeatures2d.SIFT_create,
+                              "ROOTSIFT": RootSIFT,
+                              "SURF": cv2.xfeatures2d.SURF_create,
+                              "BRIEF": cv2.xfeatures2d.BriefDescriptorExtractor_create,
+                              "ORB": cv2.ORB_create,
+                              "BRISK": cv2.BRISK_create,
+                              "FREAK": cv2.xfeatures2d.FREAK_create
+                              }
+
+        _MATCHER_FACTORY = {"BruteForce": cv2.DESCRIPTOR_MATCHER_BRUTEFORCE,
+                           "BruteForce-SL2": cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_SL2,
+                           "BruteForce-L1": cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_L1,
+                           "BruteForce-Hamming": cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING,
+                           "FlannBased": cv2.DESCRIPTOR_MATCHER_FLANNBASED
+                           }
+
+    except AttributeError:
+        _DETECTOR_FACTORY = {"MSER": cv2.MSER_create,
+                             "FAST": cv2.FastFeatureDetector_create,
+                             "BRISK": cv2.BRISK_create,
+                             "ORB": cv2.ORB_create,
+                             "GFTT": GFTT,
+                             "HARRIS": HARRIS,
+                             "DENSE": DENSE
+                             }
+
+        _EXTRACTOR_FACTORY = {"ORB": cv2.ORB_create,
+                              "BRISK": cv2.BRISK_create
+                              }
+
+    _CONTRIB_FUNCS = {"SIFT", "ROOTSIFT", "SURF", "STAR", "BRIEF", "FREAK"}
+
+
+    def FeatureDetector_create(detector, *args, **kw_args):
+        """
+
+        :param detector: string of the type of keypoint detector to return
+        :param args: positional arguments for detector
+        :param kw_args: keyword arguments for detector
+        :return: the key point detector object
+        """
+        try:
+            detr = _DETECTOR_FACTORY[detector.upper()]
+        except KeyError:
+            if detector.upper() in _CONTRIB_FUNCS:
+                msg = "OpenCV needs to be compiled with opencv_contrib to support {}".format(detector)
+                raise AttributeError(msg)
+            raise AttributeError("{} not a supported detector".format(detector))
+
+        return detr(*args, **kw_args)
+
+
+    def DescriptorExtractor_create(extractor, *args, **kw_args):
+        """
+
+        :param extractor: string of the type of descriptor extractor to return
+        :param args: positional arguments for extractor
+        :param kw_args: keyword arguments for extractor
+        :return: the key extractor object
+        """
+        try:
+            extr = _EXTRACTOR_FACTORY[extractor.upper()]
+        except KeyError:
+            if extractor.upper() in _CONTRIB_FUNCS:
+                msg = "OpenCV needs to be compiled with opencv_contrib to support {}".format(extractor)
+                raise AttributeError(msg)
+            raise AttributeError("{} not a supported extractor".format(extractor))
+
+        return extr(*args, **kw_args)
+
+    def DescriptorMatcher_create(matcher):
+        """
+
+        :param matcher: string of the type of descriptor matcher to return
+        :return: the matcher int
+        """
+        try:
+            extr = _MATCHER_FACTORY[matcher]
+        except KeyError:
+            raise AttributeError("{} not a supported matcher".format(matcher))
+
+        return cv2.DescriptorMatcher_create(extr)
Index: app/venv/Lib/site-packages/imutils/feature/gftt.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/venv/Lib/site-packages/imutils/feature/gftt.py	(date 1605210046604)
+++ app/venv/Lib/site-packages/imutils/feature/gftt.py	(date 1605210046604)
@@ -0,0 +1,22 @@
+import cv2
+from .helpers import corners_to_keypoints
+
+
+class GFTT:
+    def __init__(self, maxCorners=0, qualityLevel=0.01, minDistance=1,
+                 mask=None, blockSize=3, useHarrisDetector=False, k=0.04):
+        self.maxCorners = maxCorners
+        self.qualityLevel = qualityLevel
+        self.minDistance = minDistance
+        self.mask = mask
+        self.blockSize = blockSize
+        self.useHarrisDetector = useHarrisDetector
+        self.k = k
+
+    def detect(self, img):
+        cnrs = cv2.goodFeaturesToTrack(img, self.maxCorners, self.qualityLevel, self.minDistance,
+                                       mask=self.mask, blockSize=self.blockSize,
+                                       useHarrisDetector=self.useHarrisDetector, k=self.k)
+
+        return corners_to_keypoints(cnrs)
+
Index: app/venv/Lib/site-packages/imutils/feature/harris.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/venv/Lib/site-packages/imutils/feature/harris.py	(date 1605210046623)
+++ app/venv/Lib/site-packages/imutils/feature/harris.py	(date 1605210046623)
@@ -0,0 +1,26 @@
+import cv2
+import numpy as np
+from .helpers import corners_to_keypoints
+
+
+class HARRIS:
+    def __init__(self, blockSize=2, apertureSize=3, k=0.1, T=0.02):
+        self.blockSize = blockSize
+        self.apertureSize = apertureSize
+        self.k = k
+        self.T = T
+
+    def detect(self, img):
+        # convert our input image to a floating point data type and then
+        # compute the Harris corner matrix
+        gray = np.float32(img)
+        H = cv2.cornerHarris(gray, self.blockSize, self.apertureSize, self.k)
+
+        # for every (x, y)-coordinate where the Harris value is above the
+        # threshold, create a keypoint (the Harris detector returns
+        # keypoint size a 3-pixel radius)
+        kps = np.argwhere(H > self.T * H.max())
+        kps = [cv2.KeyPoint(pt[1], pt[0], 3) for pt in kps]
+
+        # return the Harris keypoints
+        return kps
Index: app/venv/Lib/site-packages/imutils/feature/helpers.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/venv/Lib/site-packages/imutils/feature/helpers.py	(date 1605210046618)
+++ app/venv/Lib/site-packages/imutils/feature/helpers.py	(date 1605210046618)
@@ -0,0 +1,11 @@
+# import the necesasry packages
+import cv2
+
+def corners_to_keypoints(corners):
+    """function to take the corners from cv2.GoodFeaturesToTrack and return cv2.KeyPoints"""
+    if corners is None:
+        keypoints = []
+    else:
+        keypoints = [cv2.KeyPoint(kp[0][0], kp[0][1], 1) for kp in corners]
+
+    return keypoints
Index: app/venv/Lib/site-packages/imutils/feature/rootsift.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/venv/Lib/site-packages/imutils/feature/rootsift.py	(date 1605210046635)
+++ app/venv/Lib/site-packages/imutils/feature/rootsift.py	(date 1605210046635)
@@ -0,0 +1,31 @@
+# import the necessary packages
+from __future__ import absolute_import
+import numpy as np
+import cv2
+from ..convenience import is_cv2
+
+class RootSIFT:
+	def __init__(self):
+		# initialize the SIFT feature extractor for OpenCV 2.4
+		if is_cv2():
+			self.extractor = cv2.DescriptorExtractor_create("SIFT")
+
+		# otherwise initialize the SIFT feature extractor for OpenCV 3+
+		else:
+			self.extractor = cv2.xfeatures2d.SIFT_create()
+
+	def compute(self, image, kps, eps=1e-7):
+		# compute SIFT descriptors
+		(kps, descs) = self.extractor.compute(image, kps)
+
+		# if there are no keypoints or descriptors, return an empty tuple
+		if len(kps) == 0:
+			return ([], None)
+
+		# apply the Hellinger kernel by first L1-normalizing and taking the
+		# square-root
+		descs /= (descs.sum(axis=1, keepdims=True) + eps)
+		descs = np.sqrt(descs)
+
+		# return a tuple of the keypoints and descriptors
+		return (kps, descs)
\ No newline at end of file
Index: app/venv/Lib/site-packages/imutils/feature/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/venv/Lib/site-packages/imutils/feature/__init__.py	(date 1605210046630)
+++ app/venv/Lib/site-packages/imutils/feature/__init__.py	(date 1605210046630)
@@ -0,0 +1,8 @@
+from .helpers import corners_to_keypoints
+from .factories import FeatureDetector_create
+from .factories import DescriptorExtractor_create
+from .factories import DescriptorMatcher_create
+from .dense import DENSE
+from .gftt import GFTT
+from .harris import HARRIS
+from .rootsift import RootSIFT
Index: app/venv/Lib/site-packages/imutils/face_utils/helpers.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/venv/Lib/site-packages/imutils/face_utils/helpers.py	(date 1605210046641)
+++ app/venv/Lib/site-packages/imutils/face_utils/helpers.py	(date 1605210046641)
@@ -0,0 +1,95 @@
+# import the necessary packages
+from collections import OrderedDict
+import numpy as np
+import cv2
+
+# define a dictionary that maps the indexes of the facial
+# landmarks to specific face regions
+
+#For dlib’s 68-point facial landmark detector:
+FACIAL_LANDMARKS_68_IDXS = OrderedDict([
+	("mouth", (48, 68)),
+	("inner_mouth", (60, 68)),
+	("right_eyebrow", (17, 22)),
+	("left_eyebrow", (22, 27)),
+	("right_eye", (36, 42)),
+	("left_eye", (42, 48)),
+	("nose", (27, 36)),
+	("jaw", (0, 17))
+])
+
+#For dlib’s 5-point facial landmark detector:
+FACIAL_LANDMARKS_5_IDXS = OrderedDict([
+	("right_eye", (2, 3)),
+	("left_eye", (0, 1)),
+	("nose", (4))
+])
+
+# in order to support legacy code, we'll default the indexes to the
+# 68-point model
+FACIAL_LANDMARKS_IDXS = FACIAL_LANDMARKS_68_IDXS
+
+def rect_to_bb(rect):
+	# take a bounding predicted by dlib and convert it
+	# to the format (x, y, w, h) as we would normally do
+	# with OpenCV
+	x = rect.left()
+	y = rect.top()
+	w = rect.right() - x
+	h = rect.bottom() - y
+
+	# return a tuple of (x, y, w, h)
+	return (x, y, w, h)
+
+def shape_to_np(shape, dtype="int"):
+	# initialize the list of (x, y)-coordinates
+	coords = np.zeros((shape.num_parts, 2), dtype=dtype)
+
+	# loop over all facial landmarks and convert them
+	# to a 2-tuple of (x, y)-coordinates
+	for i in range(0, shape.num_parts):
+		coords[i] = (shape.part(i).x, shape.part(i).y)
+
+	# return the list of (x, y)-coordinates
+	return coords
+
+def visualize_facial_landmarks(image, shape, colors=None, alpha=0.75):
+	# create two copies of the input image -- one for the
+	# overlay and one for the final output image
+	overlay = image.copy()
+	output = image.copy()
+
+	# if the colors list is None, initialize it with a unique
+	# color for each facial landmark region
+	if colors is None:
+		colors = [(19, 199, 109), (79, 76, 240), (230, 159, 23),
+			(168, 100, 168), (158, 163, 32),
+			(163, 38, 32), (180, 42, 220)]
+
+	# loop over the facial landmark regions individually
+	for (i, name) in enumerate(FACIAL_LANDMARKS_IDXS.keys()):
+		# grab the (x, y)-coordinates associated with the
+		# face landmark
+		(j, k) = FACIAL_LANDMARKS_IDXS[name]
+		pts = shape[j:k]
+
+		# check if are supposed to draw the jawline
+		if name == "jaw":
+			# since the jawline is a non-enclosed facial region,
+			# just draw lines between the (x, y)-coordinates
+			for l in range(1, len(pts)):
+				ptA = tuple(pts[l - 1])
+				ptB = tuple(pts[l])
+				cv2.line(overlay, ptA, ptB, colors[i], 2)
+
+		# otherwise, compute the convex hull of the facial
+		# landmark coordinates points and display it
+		else:
+			hull = cv2.convexHull(pts)
+			cv2.drawContours(overlay, [hull], -1, colors[i], -1)
+
+	# apply the transparent overlay
+	cv2.addWeighted(overlay, alpha, output, 1 - alpha, 0, output)
+
+	# return the output image
+	return output
Index: app/venv/Lib/site-packages/imutils/face_utils/facealigner.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/venv/Lib/site-packages/imutils/face_utils/facealigner.py	(date 1605210046648)
+++ app/venv/Lib/site-packages/imutils/face_utils/facealigner.py	(date 1605210046648)
@@ -0,0 +1,82 @@
+# import the necessary packages
+from .helpers import FACIAL_LANDMARKS_68_IDXS
+from .helpers import FACIAL_LANDMARKS_5_IDXS
+from .helpers import shape_to_np
+import numpy as np
+import cv2
+
+class FaceAligner:
+	def __init__(self, predictor, desiredLeftEye=(0.35, 0.35),
+		desiredFaceWidth=256, desiredFaceHeight=None):
+		# store the facial landmark predictor, desired output left
+		# eye position, and desired output face width + height
+		self.predictor = predictor
+		self.desiredLeftEye = desiredLeftEye
+		self.desiredFaceWidth = desiredFaceWidth
+		self.desiredFaceHeight = desiredFaceHeight
+
+		# if the desired face height is None, set it to be the
+		# desired face width (normal behavior)
+		if self.desiredFaceHeight is None:
+			self.desiredFaceHeight = self.desiredFaceWidth
+
+	def align(self, image, gray, rect):
+		# convert the landmark (x, y)-coordinates to a NumPy array
+		shape = self.predictor(gray, rect)
+		shape = shape_to_np(shape)
+		
+		#simple hack ;)
+		if (len(shape)==68):
+			# extract the left and right eye (x, y)-coordinates
+			(lStart, lEnd) = FACIAL_LANDMARKS_68_IDXS["left_eye"]
+			(rStart, rEnd) = FACIAL_LANDMARKS_68_IDXS["right_eye"]
+		else:
+			(lStart, lEnd) = FACIAL_LANDMARKS_5_IDXS["left_eye"]
+			(rStart, rEnd) = FACIAL_LANDMARKS_5_IDXS["right_eye"]
+			
+		leftEyePts = shape[lStart:lEnd]
+		rightEyePts = shape[rStart:rEnd]
+
+		# compute the center of mass for each eye
+		leftEyeCenter = leftEyePts.mean(axis=0).astype("int")
+		rightEyeCenter = rightEyePts.mean(axis=0).astype("int")
+
+		# compute the angle between the eye centroids
+		dY = rightEyeCenter[1] - leftEyeCenter[1]
+		dX = rightEyeCenter[0] - leftEyeCenter[0]
+		angle = np.degrees(np.arctan2(dY, dX)) - 180
+
+		# compute the desired right eye x-coordinate based on the
+		# desired x-coordinate of the left eye
+		desiredRightEyeX = 1.0 - self.desiredLeftEye[0]
+
+		# determine the scale of the new resulting image by taking
+		# the ratio of the distance between eyes in the *current*
+		# image to the ratio of distance between eyes in the
+		# *desired* image
+		dist = np.sqrt((dX ** 2) + (dY ** 2))
+		desiredDist = (desiredRightEyeX - self.desiredLeftEye[0])
+		desiredDist *= self.desiredFaceWidth
+		scale = desiredDist / dist
+
+		# compute center (x, y)-coordinates (i.e., the median point)
+		# between the two eyes in the input image
+		eyesCenter = ((leftEyeCenter[0] + rightEyeCenter[0]) // 2,
+			(leftEyeCenter[1] + rightEyeCenter[1]) // 2)
+
+		# grab the rotation matrix for rotating and scaling the face
+		M = cv2.getRotationMatrix2D(eyesCenter, angle, scale)
+
+		# update the translation component of the matrix
+		tX = self.desiredFaceWidth * 0.5
+		tY = self.desiredFaceHeight * self.desiredLeftEye[1]
+		M[0, 2] += (tX - eyesCenter[0])
+		M[1, 2] += (tY - eyesCenter[1])
+
+		# apply the affine transformation
+		(w, h) = (self.desiredFaceWidth, self.desiredFaceHeight)
+		output = cv2.warpAffine(image, M, (w, h),
+			flags=cv2.INTER_CUBIC)
+
+		# return the aligned face
+		return output
Index: app/venv/Lib/site-packages/imutils/face_utils/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/venv/Lib/site-packages/imutils/face_utils/__init__.py	(date 1605210046660)
+++ app/venv/Lib/site-packages/imutils/face_utils/__init__.py	(date 1605210046660)
@@ -0,0 +1,8 @@
+# import the necessary packages
+from .helpers import FACIAL_LANDMARKS_68_IDXS
+from .helpers import FACIAL_LANDMARKS_5_IDXS
+from .helpers import FACIAL_LANDMARKS_IDXS
+from .helpers import rect_to_bb
+from .helpers import shape_to_np
+from .helpers import visualize_facial_landmarks
+from .facealigner import FaceAligner
Index: app/venv/Lib/site-packages/imutils-0.5.3-py3.8.egg-info/dependency_links.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/venv/Lib/site-packages/imutils-0.5.3-py3.8.egg-info/dependency_links.txt	(date 1605210046655)
+++ app/venv/Lib/site-packages/imutils-0.5.3-py3.8.egg-info/dependency_links.txt	(date 1605210046655)
@@ -0,0 +1,1 @@
+
Index: app/venv/Lib/site-packages/imutils-0.5.3-py3.8.egg-info/installed-files.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/venv/Lib/site-packages/imutils-0.5.3-py3.8.egg-info/installed-files.txt	(date 1605210046671)
+++ app/venv/Lib/site-packages/imutils-0.5.3-py3.8.egg-info/installed-files.txt	(date 1605210046671)
@@ -0,0 +1,61 @@
+..\..\..\Scripts\range-detector
+..\imutils\__init__.py
+..\imutils\__pycache__\__init__.cpython-38.pyc
+..\imutils\__pycache__\contours.cpython-38.pyc
+..\imutils\__pycache__\convenience.cpython-38.pyc
+..\imutils\__pycache__\encodings.cpython-38.pyc
+..\imutils\__pycache__\meta.cpython-38.pyc
+..\imutils\__pycache__\object_detection.cpython-38.pyc
+..\imutils\__pycache__\paths.cpython-38.pyc
+..\imutils\__pycache__\perspective.cpython-38.pyc
+..\imutils\__pycache__\text.cpython-38.pyc
+..\imutils\contours.py
+..\imutils\convenience.py
+..\imutils\encodings.py
+..\imutils\face_utils\__init__.py
+..\imutils\face_utils\__pycache__\__init__.cpython-38.pyc
+..\imutils\face_utils\__pycache__\facealigner.cpython-38.pyc
+..\imutils\face_utils\__pycache__\helpers.cpython-38.pyc
+..\imutils\face_utils\facealigner.py
+..\imutils\face_utils\helpers.py
+..\imutils\feature\__init__.py
+..\imutils\feature\__pycache__\__init__.cpython-38.pyc
+..\imutils\feature\__pycache__\dense.cpython-38.pyc
+..\imutils\feature\__pycache__\factories.cpython-38.pyc
+..\imutils\feature\__pycache__\gftt.cpython-38.pyc
+..\imutils\feature\__pycache__\harris.cpython-38.pyc
+..\imutils\feature\__pycache__\helpers.cpython-38.pyc
+..\imutils\feature\__pycache__\rootsift.cpython-38.pyc
+..\imutils\feature\dense.py
+..\imutils\feature\factories.py
+..\imutils\feature\gftt.py
+..\imutils\feature\harris.py
+..\imutils\feature\helpers.py
+..\imutils\feature\rootsift.py
+..\imutils\io\__init__.py
+..\imutils\io\__pycache__\__init__.cpython-38.pyc
+..\imutils\io\__pycache__\tempfile.cpython-38.pyc
+..\imutils\io\tempfile.py
+..\imutils\meta.py
+..\imutils\object_detection.py
+..\imutils\paths.py
+..\imutils\perspective.py
+..\imutils\text.py
+..\imutils\video\__init__.py
+..\imutils\video\__pycache__\__init__.cpython-38.pyc
+..\imutils\video\__pycache__\count_frames.cpython-38.pyc
+..\imutils\video\__pycache__\filevideostream.cpython-38.pyc
+..\imutils\video\__pycache__\fps.cpython-38.pyc
+..\imutils\video\__pycache__\pivideostream.cpython-38.pyc
+..\imutils\video\__pycache__\videostream.cpython-38.pyc
+..\imutils\video\__pycache__\webcamvideostream.cpython-38.pyc
+..\imutils\video\count_frames.py
+..\imutils\video\filevideostream.py
+..\imutils\video\fps.py
+..\imutils\video\pivideostream.py
+..\imutils\video\videostream.py
+..\imutils\video\webcamvideostream.py
+PKG-INFO
+SOURCES.txt
+dependency_links.txt
+top_level.txt
Index: app/venv/Lib/site-packages/imutils-0.5.3-py3.8.egg-info/PKG-INFO
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/venv/Lib/site-packages/imutils-0.5.3-py3.8.egg-info/PKG-INFO	(date 1605210046666)
+++ app/venv/Lib/site-packages/imutils-0.5.3-py3.8.egg-info/PKG-INFO	(date 1605210046666)
@@ -0,0 +1,12 @@
+Metadata-Version: 1.1
+Name: imutils
+Version: 0.5.3
+Summary: A series of convenience functions to make basic image processing functions such as translation, rotation, resizing, skeletonization, displaying Matplotlib images, sorting contours, detecting edges, and much more easier with OpenCV and both Python 2.7 and Python 3.
+Home-page: https://github.com/jrosebr1/imutils
+Author: Adrian Rosebrock
+Author-email: adrian@pyimagesearch.com
+License: UNKNOWN
+Download-URL: https://github.com/jrosebr1/imutils/tarball/0.1
+Description: UNKNOWN
+Keywords: computer vision,image processing,opencv,matplotlib
+Platform: UNKNOWN
Index: app/venv/Lib/site-packages/imutils-0.5.3-py3.8.egg-info/SOURCES.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/venv/Lib/site-packages/imutils-0.5.3-py3.8.egg-info/SOURCES.txt	(date 1605210046680)
+++ app/venv/Lib/site-packages/imutils-0.5.3-py3.8.egg-info/SOURCES.txt	(date 1605210046680)
@@ -0,0 +1,35 @@
+setup.cfg
+setup.py
+bin/range-detector
+imutils/__init__.py
+imutils/contours.py
+imutils/convenience.py
+imutils/encodings.py
+imutils/meta.py
+imutils/object_detection.py
+imutils/paths.py
+imutils/perspective.py
+imutils/text.py
+imutils.egg-info/PKG-INFO
+imutils.egg-info/SOURCES.txt
+imutils.egg-info/dependency_links.txt
+imutils.egg-info/top_level.txt
+imutils/face_utils/__init__.py
+imutils/face_utils/facealigner.py
+imutils/face_utils/helpers.py
+imutils/feature/__init__.py
+imutils/feature/dense.py
+imutils/feature/factories.py
+imutils/feature/gftt.py
+imutils/feature/harris.py
+imutils/feature/helpers.py
+imutils/feature/rootsift.py
+imutils/io/__init__.py
+imutils/io/tempfile.py
+imutils/video/__init__.py
+imutils/video/count_frames.py
+imutils/video/filevideostream.py
+imutils/video/fps.py
+imutils/video/pivideostream.py
+imutils/video/videostream.py
+imutils/video/webcamvideostream.py
\ No newline at end of file
Index: app/venv/Lib/site-packages/imutils-0.5.3-py3.8.egg-info/top_level.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/venv/Lib/site-packages/imutils-0.5.3-py3.8.egg-info/top_level.txt	(date 1605210046676)
+++ app/venv/Lib/site-packages/imutils-0.5.3-py3.8.egg-info/top_level.txt	(date 1605210046676)
@@ -0,0 +1,1 @@
+imutils
Index: app/venv/Scripts/range-detector
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/venv/Scripts/range-detector	(date 1605210046685)
+++ app/venv/Scripts/range-detector	(date 1605210046685)
@@ -0,0 +1,107 @@
+#!C:\Users\Koolk\AndroidStudioProjects\Braille2Text\app\venv\Scripts\python.exe
+# -*- coding: utf-8 -*-
+
+# USAGE: You need to specify a filter and "only one" image source
+#
+# (python) range-detector --filter RGB --image /path/to/image.png
+# or
+# (python) range-detector --filter HSV --webcam
+
+import cv2
+import argparse
+from operator import xor
+
+
+def callback(value):
+    pass
+
+
+def setup_trackbars(range_filter):
+    cv2.namedWindow("Trackbars", 0)
+
+    for i in ["MIN", "MAX"]:
+        v = 0 if i == "MIN" else 255
+
+        for j in range_filter:
+            cv2.createTrackbar("%s_%s" % (j, i), "Trackbars", v, 255, callback)
+
+
+def get_arguments():
+    ap = argparse.ArgumentParser()
+    ap.add_argument('-f', '--filter', required=True,
+                    help='Range filter. RGB or HSV')
+    ap.add_argument('-i', '--image', required=False,
+                    help='Path to the image')
+    ap.add_argument('-w', '--webcam', required=False,
+                    help='Use webcam', action='store_true')
+    ap.add_argument('-p', '--preview', required=False,
+                    help='Show a preview of the image after applying the mask',
+                    action='store_true')
+    args = vars(ap.parse_args())
+
+    if not xor(bool(args['image']), bool(args['webcam'])):
+        ap.error("Please specify only one image source")
+
+    if not args['filter'].upper() in ['RGB', 'HSV']:
+        ap.error("Please speciy a correct filter.")
+
+    return args
+
+
+def get_trackbar_values(range_filter):
+    values = []
+
+    for i in ["MIN", "MAX"]:
+        for j in range_filter:
+            v = cv2.getTrackbarPos("%s_%s" % (j, i), "Trackbars")
+            values.append(v)
+
+    return values
+
+
+def main():
+    args = get_arguments()
+
+    range_filter = args['filter'].upper()
+
+    if args['image']:
+        image = cv2.imread(args['image'])
+
+        if range_filter == 'RGB':
+            frame_to_thresh = image.copy()
+        else:
+            frame_to_thresh = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
+    else:
+        camera = cv2.VideoCapture(0)
+
+    setup_trackbars(range_filter)
+
+    while True:
+        if args['webcam']:
+            ret, image = camera.read()
+
+            if not ret:
+                break
+
+            if range_filter == 'RGB':
+                frame_to_thresh = image.copy()
+            else:
+                frame_to_thresh = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
+
+        v1_min, v2_min, v3_min, v1_max, v2_max, v3_max = get_trackbar_values(range_filter)
+
+        thresh = cv2.inRange(frame_to_thresh, (v1_min, v2_min, v3_min), (v1_max, v2_max, v3_max))
+
+        if args['preview']:
+            preview = cv2.bitwise_and(image, image, mask=thresh)
+            cv2.imshow("Preview", preview)
+        else:
+            cv2.imshow("Original", image)
+            cv2.imshow("Thresh", thresh)
+
+        if cv2.waitKey(1) & 0xFF is ord('q'):
+            break
+
+
+if __name__ == '__main__':
+    main()
Index: app/venv/Lib/site-packages/imutils/encodings.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/venv/Lib/site-packages/imutils/encodings.py	(date 1605210046456)
+++ app/venv/Lib/site-packages/imutils/encodings.py	(date 1605210046456)
@@ -0,0 +1,35 @@
+# import the necessary packages
+import numpy as np
+import base64
+import json
+import sys
+
+def base64_encode_image(a):
+	# return a JSON-encoded list of the base64 encoded image, image data
+	# type, and image shape
+	#return json.dumps([base64_encode_array(a), str(a.dtype), a.shape])
+	return json.dumps([base64_encode_array(a).decode("utf-8"), str(a.dtype),
+		a.shape])
+
+def base64_decode_image(a):
+	# grab the array, data type, and shape from the JSON-decoded object
+	(a, dtype, shape) = json.loads(a)
+
+	# if this is Python 3, then we need the extra step of encoding the
+	# string as byte object
+	if sys.version_info.major == 3:
+		a = bytes(a, encoding="utf-8")
+
+	# set the correct data type and reshape the matrix into an image
+	a = base64_decode_array(a, dtype).reshape(shape)
+
+	# return the loaded image
+	return a
+
+def base64_encode_array(a):
+	# return the base64 encoded array
+	return base64.b64encode(a)
+
+def base64_decode_array(a, dtype):
+	# decode and return the array
+	return np.frombuffer(base64.decodestring(a), dtype=dtype)
\ No newline at end of file
Index: app/venv/Lib/site-packages/imutils/contours.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/venv/Lib/site-packages/imutils/contours.py	(date 1605210046446)
+++ app/venv/Lib/site-packages/imutils/contours.py	(date 1605210046446)
@@ -0,0 +1,44 @@
+# author:    Adrian Rosebrock
+# website:   http://www.pyimagesearch.com
+
+# import the necessary packages
+import cv2
+
+def sort_contours(cnts, method="left-to-right"):
+    # initialize the reverse flag and sort index
+    reverse = False
+    i = 0
+
+    # handle if we need to sort in reverse
+    if method == "right-to-left" or method == "bottom-to-top":
+        reverse = True
+
+    # handle if we are sorting against the y-coordinate rather than
+    # the x-coordinate of the bounding box
+    if method == "top-to-bottom" or method == "bottom-to-top":
+        i = 1
+
+    # construct the list of bounding boxes and sort them from top to
+    # bottom
+    boundingBoxes = [cv2.boundingRect(c) for c in cnts]
+    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),
+                                        key=lambda b: b[1][i], reverse=reverse))
+
+    # return the list of sorted contours and bounding boxes
+    return cnts, boundingBoxes
+
+
+def label_contour(image, c, i, color=(0, 255, 0), thickness=2):
+    # compute the center of the contour area and draw a circle
+    # representing the center
+    M = cv2.moments(c)
+    cX = int(M["m10"] / M["m00"])
+    cY = int(M["m01"] / M["m00"])
+
+    # draw the contour and label number on the image
+    cv2.drawContours(image, [c], -1, color, thickness)
+    cv2.putText(image, "#{}".format(i + 1), (cX - 20, cY), cv2.FONT_HERSHEY_SIMPLEX,
+                1.0, (255, 255, 255), 2)
+
+    # return the image with the contour number drawn on it
+    return image
Index: app/venv/Lib/site-packages/imutils/meta.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/venv/Lib/site-packages/imutils/meta.py	(date 1605210046474)
+++ app/venv/Lib/site-packages/imutils/meta.py	(date 1605210046474)
@@ -0,0 +1,26 @@
+# author:    Adrian Rosebrock
+# website:   http://www.pyimagesearch.com
+
+# import the necessary packages
+from __future__ import print_function
+import cv2
+import re
+
+def find_function(name, pretty_print=True, module=None):
+	# if the module is None, initialize it to to the root `cv2`
+	# library
+	if module is None:
+		module = cv2
+
+	# grab all function names that contain `name` from the module
+	p = ".*{}.*".format(name)
+	filtered = filter(lambda x: re.search(p, x, re.IGNORECASE), dir(module))
+	
+	# check to see if the filtered names should be returned to the
+	# calling function
+	if not pretty_print:
+		return filtered
+
+	# otherwise, loop over the function names and print them
+	for (i, funcName) in enumerate(filtered):
+		print("{}. {}".format(i + 1, funcName))
\ No newline at end of file
Index: app/venv/Lib/site-packages/imutils/convenience.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/venv/Lib/site-packages/imutils/convenience.py	(date 1605210046467)
+++ app/venv/Lib/site-packages/imutils/convenience.py	(date 1605210046467)
@@ -0,0 +1,319 @@
+# author:    Adrian Rosebrock
+# website:   http://www.pyimagesearch.com
+
+# import the necessary packages
+import numpy as np
+import cv2
+import sys
+
+# import any special Python 2.7 packages
+if sys.version_info.major == 2:
+    from urllib import urlopen
+
+# import any special Python 3 packages
+elif sys.version_info.major == 3:
+    from urllib.request import urlopen
+
+def translate(image, x, y):
+    # define the translation matrix and perform the translation
+    M = np.float32([[1, 0, x], [0, 1, y]])
+    shifted = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))
+
+    # return the translated image
+    return shifted
+
+def rotate(image, angle, center=None, scale=1.0):
+    # grab the dimensions of the image
+    (h, w) = image.shape[:2]
+
+    # if the center is None, initialize it as the center of
+    # the image
+    if center is None:
+        center = (w // 2, h // 2)
+
+    # perform the rotation
+    M = cv2.getRotationMatrix2D(center, angle, scale)
+    rotated = cv2.warpAffine(image, M, (w, h))
+
+    # return the rotated image
+    return rotated
+
+def rotate_bound(image, angle):
+    # grab the dimensions of the image and then determine the
+    # center
+    (h, w) = image.shape[:2]
+    (cX, cY) = (w / 2, h / 2)
+
+    # grab the rotation matrix (applying the negative of the
+    # angle to rotate clockwise), then grab the sine and cosine
+    # (i.e., the rotation components of the matrix)
+    M = cv2.getRotationMatrix2D((cX, cY), -angle, 1.0)
+    cos = np.abs(M[0, 0])
+    sin = np.abs(M[0, 1])
+
+    # compute the new bounding dimensions of the image
+    nW = int((h * sin) + (w * cos))
+    nH = int((h * cos) + (w * sin))
+
+    # adjust the rotation matrix to take into account translation
+    M[0, 2] += (nW / 2) - cX
+    M[1, 2] += (nH / 2) - cY
+
+    # perform the actual rotation and return the image
+    return cv2.warpAffine(image, M, (nW, nH))
+
+def resize(image, width=None, height=None, inter=cv2.INTER_AREA):
+    # initialize the dimensions of the image to be resized and
+    # grab the image size
+    dim = None
+    (h, w) = image.shape[:2]
+
+    # if both the width and height are None, then return the
+    # original image
+    if width is None and height is None:
+        return image
+
+    # check to see if the width is None
+    if width is None:
+        # calculate the ratio of the height and construct the
+        # dimensions
+        r = height / float(h)
+        dim = (int(w * r), height)
+
+    # otherwise, the height is None
+    else:
+        # calculate the ratio of the width and construct the
+        # dimensions
+        r = width / float(w)
+        dim = (width, int(h * r))
+
+    # resize the image
+    resized = cv2.resize(image, dim, interpolation=inter)
+
+    # return the resized image
+    return resized
+
+def skeletonize(image, size, structuring=cv2.MORPH_RECT):
+    # determine the area (i.e. total number of pixels in the image),
+    # initialize the output skeletonized image, and construct the
+    # morphological structuring element
+    area = image.shape[0] * image.shape[1]
+    skeleton = np.zeros(image.shape, dtype="uint8")
+    elem = cv2.getStructuringElement(structuring, size)
+
+    # keep looping until the erosions remove all pixels from the
+    # image
+    while True:
+        # erode and dilate the image using the structuring element
+        eroded = cv2.erode(image, elem)
+        temp = cv2.dilate(eroded, elem)
+
+        # subtract the temporary image from the original, eroded
+        # image, then take the bitwise 'or' between the skeleton
+        # and the temporary image
+        temp = cv2.subtract(image, temp)
+        skeleton = cv2.bitwise_or(skeleton, temp)
+        image = eroded.copy()
+
+        # if there are no more 'white' pixels in the image, then
+        # break from the loop
+        if area == area - cv2.countNonZero(image):
+            break
+
+    # return the skeletonized image
+    return skeleton
+
+def opencv2matplotlib(image):
+    # OpenCV represents images in BGR order; however, Matplotlib
+    # expects the image in RGB order, so simply convert from BGR
+    # to RGB and return
+    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
+
+def url_to_image(url, readFlag=cv2.IMREAD_COLOR):
+    # download the image, convert it to a NumPy array, and then read
+    # it into OpenCV format
+    resp = urlopen(url)
+    image = np.asarray(bytearray(resp.read()), dtype="uint8")
+    image = cv2.imdecode(image, readFlag)
+
+    # return the image
+    return image
+
+def auto_canny(image, sigma=0.33):
+    # compute the median of the single channel pixel intensities
+    v = np.median(image)
+
+    # apply automatic Canny edge detection using the computed median
+    lower = int(max(0, (1.0 - sigma) * v))
+    upper = int(min(255, (1.0 + sigma) * v))
+    edged = cv2.Canny(image, lower, upper)
+
+    # return the edged image
+    return edged
+
+def grab_contours(cnts):
+    # if the length the contours tuple returned by cv2.findContours
+    # is '2' then we are using either OpenCV v2.4, v4-beta, or
+    # v4-official
+    if len(cnts) == 2:
+        cnts = cnts[0]
+
+    # if the length of the contours tuple is '3' then we are using
+    # either OpenCV v3, v4-pre, or v4-alpha
+    elif len(cnts) == 3:
+        cnts = cnts[1]
+
+    # otherwise OpenCV has changed their cv2.findContours return
+    # signature yet again and I have no idea WTH is going on
+    else:
+        raise Exception(("Contours tuple must have length 2 or 3, "
+            "otherwise OpenCV changed their cv2.findContours return "
+            "signature yet again. Refer to OpenCV's documentation "
+            "in that case"))
+
+    # return the actual contours array
+    return cnts
+
+def is_cv2(or_better=False):
+    # grab the OpenCV major version number
+    major = get_opencv_major_version()
+
+    # check to see if we are using *at least* OpenCV 2
+    if or_better:
+        return major >= 2
+
+    # otherwise we want to check for *strictly* OpenCV 2
+    return major == 2
+
+def is_cv3(or_better=False):
+    # grab the OpenCV major version number
+    major = get_opencv_major_version()
+
+    # check to see if we are using *at least* OpenCV 3
+    if or_better:
+        return major >= 3
+
+    # otherwise we want to check for *strictly* OpenCV 3
+    return major == 3
+
+def is_cv4(or_better=False):
+    # grab the OpenCV major version number
+    major = get_opencv_major_version()
+
+    # check to see if we are using *at least* OpenCV 4
+    if or_better:
+        return major >= 4
+
+    # otherwise we want to check for *strictly* OpenCV 4
+    return major == 4
+
+def get_opencv_major_version(lib=None):
+    # if the supplied library is None, import OpenCV
+    if lib is None:
+        import cv2 as lib
+
+    # return the major version number
+    return int(lib.__version__.split(".")[0])
+
+def check_opencv_version(major, lib=None):
+    # this function may be removed in a future release as we now
+    # use the get_opencv_major_function to obtain the current OpenCV
+    # version and then perform the actual version check *within* the
+    # respective function
+    import warnings
+    message = """
+        The check_opencv_version function is deprecated and may be
+        removed in a future release. Use at your own risk.
+    """
+    warnings.warn(message, DeprecationWarning, stacklevel=2)
+    
+    # if the supplied library is None, import OpenCV
+    if lib is None:
+        import cv2 as lib
+        
+    # return whether or not the current OpenCV version matches the
+    # major version number
+    return lib.__version__.startswith(major)
+
+def build_montages(image_list, image_shape, montage_shape):
+    """
+    ---------------------------------------------------------------------------------------------
+    author: Kyle Hounslow
+    ---------------------------------------------------------------------------------------------
+    Converts a list of single images into a list of 'montage' images of specified rows and columns.
+    A new montage image is started once rows and columns of montage image is filled.
+    Empty space of incomplete montage images are filled with black pixels
+    ---------------------------------------------------------------------------------------------
+    :param image_list: python list of input images
+    :param image_shape: tuple, size each image will be resized to for display (width, height)
+    :param montage_shape: tuple, shape of image montage (width, height)
+    :return: list of montage images in numpy array format
+    ---------------------------------------------------------------------------------------------
+
+    example usage:
+
+    # load single image
+    img = cv2.imread('lena.jpg')
+    # duplicate image 25 times
+    num_imgs = 25
+    img_list = []
+    for i in xrange(num_imgs):
+        img_list.append(img)
+    # convert image list into a montage of 256x256 images tiled in a 5x5 montage
+    montages = make_montages_of_images(img_list, (256, 256), (5, 5))
+    # iterate through montages and display
+    for montage in montages:
+        cv2.imshow('montage image', montage)
+        cv2.waitKey(0)
+
+    ----------------------------------------------------------------------------------------------
+    """
+    if len(image_shape) != 2:
+        raise Exception('image shape must be list or tuple of length 2 (rows, cols)')
+    if len(montage_shape) != 2:
+        raise Exception('montage shape must be list or tuple of length 2 (rows, cols)')
+    image_montages = []
+    # start with black canvas to draw images onto
+    montage_image = np.zeros(shape=(image_shape[1] * (montage_shape[1]), image_shape[0] * montage_shape[0], 3),
+                          dtype=np.uint8)
+    cursor_pos = [0, 0]
+    start_new_img = False
+    for img in image_list:
+        if type(img).__module__ != np.__name__:
+            raise Exception('input of type {} is not a valid numpy array'.format(type(img)))
+        start_new_img = False
+        img = cv2.resize(img, image_shape)
+        # draw image to black canvas
+        montage_image[cursor_pos[1]:cursor_pos[1] + image_shape[1], cursor_pos[0]:cursor_pos[0] + image_shape[0]] = img
+        cursor_pos[0] += image_shape[0]  # increment cursor x position
+        if cursor_pos[0] >= montage_shape[0] * image_shape[0]:
+            cursor_pos[1] += image_shape[1]  # increment cursor y position
+            cursor_pos[0] = 0
+            if cursor_pos[1] >= montage_shape[1] * image_shape[1]:
+                cursor_pos = [0, 0]
+                image_montages.append(montage_image)
+                # reset black canvas
+                montage_image = np.zeros(shape=(image_shape[1] * (montage_shape[1]), image_shape[0] * montage_shape[0], 3),
+                                      dtype=np.uint8)
+                start_new_img = True
+    if start_new_img is False:
+        image_montages.append(montage_image)  # add unfinished montage
+    return image_montages
+
+
+def adjust_brightness_contrast(image, brightness=0., contrast=0.):
+    """
+    Adjust the brightness and/or contrast of an image
+
+    :param image: OpenCV BGR image
+    :param contrast: Float, contrast adjustment with 0 meaning no change
+    :param brightness: Float, brightness adjustment with 0 meaning no change
+    """
+    beta = 0
+    # See the OpenCV docs for more info on the `beta` parameter to addWeighted
+    # https://docs.opencv.org/3.4.2/d2/de8/group__core__array.html#gafafb2513349db3bcff51f54ee5592a19
+    return cv2.addWeighted(image,
+                           1 + float(contrast) / 100.,
+                           image,
+                           beta,
+                           float(brightness))
