Index: app/src/main/res/layout/activity_camera.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"utf-8\"?>\r\n<RelativeLayout xmlns:android=\"http://schemas.android.com/apk/res/android\"\r\n    xmlns:app=\"http://schemas.android.com/apk/res-auto\"\r\n    xmlns:tools=\"http://schemas.android.com/tools\"\r\n    android:layout_width=\"match_parent\"\r\n    android:layout_height=\"match_parent\"\r\n    android:orientation=\"horizontal\"\r\n    tools:context=\".MainActivity\">\r\n\r\n    <TextureView\r\n        android:id=\"@+id/texture\"\r\n        android:layout_width=\"match_parent\"\r\n        android:layout_height=\"wrap_content\"\r\n        android:layout_above=\"@+id/btn_takepicture\"\r\n        android:layout_alignParentTop=\"true\"/>\r\n    <Button\r\n        android:id=\"@+id/btn_takepicture\"\r\n        android:layout_width=\"wrap_content\"\r\n        android:layout_height=\"wrap_content\"\r\n        android:layout_alignParentBottom=\"true\"\r\n        android:layout_centerHorizontal=\"true\"\r\n        android:layout_marginBottom=\"16dp\"\r\n        android:layout_marginTop=\"16dp\"\r\n        android:text=\"@string/take_picture\" />\r\n\r\n</RelativeLayout>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/src/main/res/layout/activity_camera.xml	(revision 48db88dd91de92680b233372650d3a88afb977cf)
+++ app/src/main/res/layout/activity_camera.xml	(date 1605234951336)
@@ -1,6 +1,5 @@
 <?xml version="1.0" encoding="utf-8"?>
 <RelativeLayout xmlns:android="http://schemas.android.com/apk/res/android"
-    xmlns:app="http://schemas.android.com/apk/res-auto"
     xmlns:tools="http://schemas.android.com/tools"
     android:layout_width="match_parent"
     android:layout_height="match_parent"
Index: app/src/main/java/com/example/braille2text/ImageProcessing.kt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>package com.example.braille2text\r\n\r\nimport android.app.Application\r\nimport com.chaquo.python.Python\r\nimport com.chaquo.python.android.AndroidPlatform\r\n\r\nclass ImageProcessing: Application() {\r\n    override fun onCreate() {\r\n        super.onCreate()\r\n        initPython()\r\n    }\r\n\r\n\r\n\r\n\r\n    private fun initPython() {\r\n        if (!Python.isStarted()) {\r\n            Python.start(AndroidPlatform(this))\r\n        }\r\n    }\r\n\r\n}\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/src/main/java/com/example/braille2text/ImageProcessing.kt	(revision 48db88dd91de92680b233372650d3a88afb977cf)
+++ app/src/main/java/com/example/braille2text/ImageProcessing.kt	(date 1605238608931)
@@ -10,13 +10,9 @@
         initPython()
     }
 
-
-
-
     private fun initPython() {
         if (!Python.isStarted()) {
             Python.start(AndroidPlatform(this))
         }
     }
-
 }
Index: app/src/main/java/com/example/braille2text/MainActivity.kt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>package com.example.braille2text\r\n\r\nimport androidx.appcompat.app.AppCompatActivity\r\nimport android.os.Bundle\r\nimport org.opencv.android.OpenCVLoader\r\nimport android.widget.Toast\r\nimport android.content.Intent\r\nimport android.view.View\r\nimport android.widget.Button\r\nimport com.chaquo.python.Python\r\nimport com.chaquo.python.android.AndroidPlatform\r\nimport kotlinx.android.synthetic.main.activity_main.*\r\n\r\nclass MainActivity : AppCompatActivity() {\r\n    private var button: Button? = null\r\n\r\n    override fun onCreate(savedInstanceState: Bundle?) {\r\n        super.onCreate(savedInstanceState)\r\n        setContentView(R.layout.activity_main)\r\n\r\n        txtPythonShow.text=getPythonHelloWorld()                      //this prints out the python function helloworld.py\r\n\r\n        if (OpenCVLoader.initDebug()) {\r\n            Toast.makeText(this, \"OpenCV successfully loaded!\", Toast.LENGTH_SHORT).show()\r\n        } else {\r\n            Toast.makeText(this, \"OpenCV cannot be loaded.\", Toast.LENGTH_SHORT).show()\r\n        }\r\n        button = findViewById<View>(R.id.button) as Button\r\n        button!!.setOnClickListener { openCameraActivity() }\r\n    }\r\n\r\n\r\n\r\n    private fun getPythonHelloWorld(): String {\r\n        val python = Python.getInstance()\r\n        val pythonFile = python.getModule(\"test\")\r\n        return pythonFile.callAttr(\"helloworld\").toString()\r\n    }\r\n\r\n    private fun openCameraActivity() {\r\n        val intent = Intent(this, CameraActivity::class.java)\r\n        startActivity(intent)\r\n    }\r\n}
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/src/main/java/com/example/braille2text/MainActivity.kt	(revision 48db88dd91de92680b233372650d3a88afb977cf)
+++ app/src/main/java/com/example/braille2text/MainActivity.kt	(date 1605238776831)
@@ -1,15 +1,15 @@
 package com.example.braille2text
 
-import androidx.appcompat.app.AppCompatActivity
-import android.os.Bundle
-import org.opencv.android.OpenCVLoader
-import android.widget.Toast
 import android.content.Intent
+import android.os.Bundle
 import android.view.View
 import android.widget.Button
+import android.widget.Toast
+import androidx.appcompat.app.AppCompatActivity
 import com.chaquo.python.Python
-import com.chaquo.python.android.AndroidPlatform
+import kotlinx.android.synthetic.main.activity_image_processing.*
 import kotlinx.android.synthetic.main.activity_main.*
+import org.opencv.android.OpenCVLoader
 
 class MainActivity : AppCompatActivity() {
     private var button: Button? = null
@@ -18,8 +18,6 @@
         super.onCreate(savedInstanceState)
         setContentView(R.layout.activity_main)
 
-        txtPythonShow.text=getPythonHelloWorld()                      //this prints out the python function helloworld.py
-
         if (OpenCVLoader.initDebug()) {
             Toast.makeText(this, "OpenCV successfully loaded!", Toast.LENGTH_SHORT).show()
         } else {
@@ -27,18 +25,18 @@
         }
         button = findViewById<View>(R.id.button) as Button
         button!!.setOnClickListener { openCameraActivity() }
-    }
-
 
-
-    private fun getPythonHelloWorld(): String {
-        val python = Python.getInstance()
-        val pythonFile = python.getModule("test")
-        return pythonFile.callAttr("helloworld").toString()
+        txtPythonShow.text = getPythonHelloWorld()                      //this prints out the python function helloworld.py
     }
 
     private fun openCameraActivity() {
         val intent = Intent(this, CameraActivity::class.java)
         startActivity(intent)
     }
+
+    private fun getPythonHelloWorld(): String {
+        val python = Python.getInstance()
+        val pythonFile = python.getModule("brailleProcessingLib")
+        return pythonFile.callAttr("helloworld").toString()
+    }
 }
\ No newline at end of file
Index: app/src/main/res/layout/activity_main.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"utf-8\"?>\r\n<RelativeLayout xmlns:android=\"http://schemas.android.com/apk/res/android\"\r\n    xmlns:app=\"http://schemas.android.com/apk/res-auto\"\r\n    xmlns:tools=\"http://schemas.android.com/tools\"\r\n    android:layout_width=\"match_parent\"\r\n    android:layout_height=\"match_parent\"\r\n    tools:context=\".MainActivity\">\r\n\r\n    <TextView\r\n        android:id=\"@+id/txtPythonShow\"\r\n        android:layout_width=\"wrap_content\"\r\n        android:layout_height=\"wrap_content\"\r\n        android:layout_alignParentTop=\"true\"\r\n        android:layout_centerHorizontal=\"true\"\r\n        android:layout_marginTop=\"212dp\"\r\n        android:text=\"Braille2Text\"\r\n        android:textColor=\"#F44336\"\r\n        android:textSize=\"30sp\" />\r\n\r\n    <Button\r\n        android:id=\"@+id/button\"\r\n        android:layout_width=\"wrap_content\"\r\n        android:layout_height=\"wrap_content\"\r\n        android:layout_alignParentBottom=\"true\"\r\n        android:layout_centerHorizontal=\"true\"\r\n        android:layout_marginBottom=\"80dp\"\r\n        android:text=\"Open Camera activity\" />\r\n\r\n</RelativeLayout>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/src/main/res/layout/activity_main.xml	(revision 48db88dd91de92680b233372650d3a88afb977cf)
+++ app/src/main/res/layout/activity_main.xml	(date 1605235859854)
@@ -1,13 +1,12 @@
 <?xml version="1.0" encoding="utf-8"?>
 <RelativeLayout xmlns:android="http://schemas.android.com/apk/res/android"
-    xmlns:app="http://schemas.android.com/apk/res-auto"
+
     xmlns:tools="http://schemas.android.com/tools"
     android:layout_width="match_parent"
     android:layout_height="match_parent"
     tools:context=".MainActivity">
 
     <TextView
-        android:id="@+id/txtPythonShow"
         android:layout_width="wrap_content"
         android:layout_height="wrap_content"
         android:layout_alignParentTop="true"
@@ -15,7 +14,8 @@
         android:layout_marginTop="212dp"
         android:text="Braille2Text"
         android:textColor="#F44336"
-        android:textSize="30sp" />
+        android:textSize="30sp"
+        tools:ignore="HardcodedText" />
 
     <Button
         android:id="@+id/button"
@@ -24,6 +24,7 @@
         android:layout_alignParentBottom="true"
         android:layout_centerHorizontal="true"
         android:layout_marginBottom="80dp"
-        android:text="Open Camera activity" />
+        android:text="Open Camera activity"
+        tools:ignore="HardcodedText" />
 
 </RelativeLayout>
\ No newline at end of file
Index: app/src/main/python/brailleProcessingLib.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from imutils.perspective import four_point_transform as FPT\r\nfrom imutils import contours\r\nfrom collections import Counter  # counter\r\nfrom skimage import io  # library to read images\r\nimport matplotlib.pyplot as plt  # library to show image to user\r\nimport numpy as np  # used to process image to arrays\r\nimport imutils  # basic image processing\r\nimport cv2  # advanced for image processing\r\nimport re  # regex\r\n\r\nFILEPATH = 'test.jpg'\r\n\r\n\r\n# test for alphabet translation / iter = 0 (test.jpg)\r\n# test for gaussian blur on nemmeth example / iter >= 3 (test2.jpg)\r\n\r\n# -----------------------FUNCTIONS------------------------- #\r\n\r\ndef get_image(FILEPATH, iter=2, width=None):\r\n    image = io.imread(FILEPATH)  # reads the url and opens the temporary image to user\r\n\r\n    if width:\r\n        image = imutils.resize(image, width)  # resizes the image per the restricted width\r\n    ans = image.copy()  # create a copy backup image\r\n\r\n    # image procesesing\r\n    accumEdged = np.zeros(image.shape[:2], dtype=\"uint8\")\r\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # convert image to black and white\r\n    blurred = cv2.GaussianBlur(gray, (5, 5), 0)  # blur to remove some of the noise\r\n    edged = cv2.Canny(blurred, 75, 200)  # get edges(converts image to easy detectable dots)\r\n    accumEdged = cv2.bitwise_or(accumEdged, edged)\r\n    ctrs = imutils.grab_contours(cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL,\r\n                                                  cv2.CHAIN_APPROX_SIMPLE))  # get contours(increases accuracy)\r\n    docCnt = None\r\n\r\n    # ensure that at least one contour was found to know an image can be processed\r\n    if len(ctrs) > 0:  # sort the contours according to their size in descending order\r\n        ctrs = sorted(ctrs, key=cv2.contourArea, reverse=True)\r\n\r\n        for c in ctrs:  # loop over the sorted contours\r\n            peri = cv2.arcLength(c, True)\r\n            approx = cv2.approxPolyDP(c, 0.02 * peri, True)  # approximate the contour\r\n\r\n            # if our approximated contour has four points, then we can assume we have found the image\r\n            if len(approx) == 4:\r\n                docCnt = approx\r\n                break\r\n    paper = image.copy()  # creates a copy of the processed image\r\n\r\n    # apply Otsu's thresholding method to binarize the image\r\n    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\r\n    kernel = np.ones((5, 5), np.uint8)\r\n\r\n    # erode and dilate to remove some of the unnecessary detail\r\n    thresh = cv2.erode(thresh, kernel, iterations=iter)\r\n    thresh = cv2.dilate(thresh, kernel, iterations=iter)\r\n\r\n    # find contours in the thresholded image\r\n    ctrs = imutils.grab_contours(\r\n        cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE))\r\n\r\n    return image, ctrs, paper, gray, edged, thresh\r\n\r\n\r\ndef get_diameter():  # shows the area of interest for the computer\r\n    boundingBoxes = [list(cv2.boundingRect(c)) for c in ctrs]\r\n    c = Counter([i[2] for i in boundingBoxes])\r\n    mode = c.most_common(1)[0][0]\r\n    if mode > 1:\r\n        diam = mode\r\n    else:\r\n        diam = c.most_common(2)[1][0]\r\n    return diam\r\n\r\n\r\ndef get_circles():  # shows the area of interest for the computer\r\n    questionCtrs = []\r\n    for c in ctrs:\r\n        (x, y, w, h) = cv2.boundingRect(c)\r\n        ar = w / float(h)\r\n\r\n        if diam * 0.8 <= w <= diam * 1.2 and 0.8 <= ar <= 1.2:  # region should be sufficiently wide, tall, and have an aspect ratio approximately equal to 1\r\n            questionCtrs.append(c)\r\n    return questionCtrs\r\n\r\n\r\ndef sort_contours(ctrs):\r\n    BB = [list(cv2.boundingRect(c)) for c in ctrs]\r\n    tol = 0.7 * diam  # choose tolerance for x, y coordinates of the bounding boxes to be binned together\r\n\r\n    def sort(i):  # change x and y coordinates of bounding boxes to their corresponding bins\r\n        S = sorted(BB, key=lambda x: x[i])\r\n        s = [b[i] for b in S]\r\n        m = s[0]\r\n\r\n        for b in S:\r\n            if m - tol < b[i] < m or m < b[i] < m + tol:\r\n                b[i] = m\r\n            elif b[i] > m + diam:\r\n                for e in s[s.index(m):]:\r\n                    if e > m + diam:\r\n                        m = e\r\n                        break\r\n        return sorted(set(s))\r\n\r\n    # lists of of x and y coordinates\r\n    xs = sort(0)\r\n    ys = sort(1)\r\n\r\n    (ctrs, BB) = zip(*sorted(zip(ctrs, BB), key=lambda b: b[1][1] * len(image) + b[1][0]))\r\n    # return the list of sorted contours and bounding boxes\r\n    return ctrs, BB, xs, ys\r\n\r\n\r\ndef draw_contours(questionCtrs):\r\n    color = (0, 255, 0)\r\n    i = 0\r\n    for q in range(len(questionCtrs)):\r\n        cv2.drawContours(paper, questionCtrs[q], -1, color, 3)\r\n        cv2.putText(paper, str(i), (boundingBoxes[q][0] + boundingBoxes[q][2] // 2,\r\n                                    boundingBoxes[q][1] + boundingBoxes[q][3] // 2),\r\n                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\r\n        i += 1\r\n\r\n\r\ndef get_spacing():\r\n    def spacing(x):\r\n        space = []\r\n        coor = [b[x] for b in boundingBoxes]\r\n        for i in range(len(coor) - 1):\r\n            c = coor[i + 1] - coor[i]\r\n            if c > diam // 2: space.append(c)\r\n        return sorted(list(set(space)))\r\n\r\n    spacingX = spacing(0)\r\n    spacingY = spacing(1)\r\n\r\n    # smallest x-seperation (between two adjacent dots in a letter)\r\n    m = min(spacingX)\r\n\r\n    c = 0\r\n\r\n    d1 = spacingX[0]\r\n    d2 = 0\r\n    d3 = 0\r\n\r\n    for x in spacingX:\r\n        if d2 == 0 and x > d1 * 1.3:\r\n            d2 = x\r\n        if d2 > 0 and x > d2 * 1.3:\r\n            d3 = x\r\n            break\r\n\r\n    linesV = []\r\n    prev = 0  # outside\r\n\r\n    linesV.append(min(xs) - (d2 - diam) / 2)\r\n\r\n    for i in range(1, len(xs)):\r\n        diff = xs[i] - xs[i - 1]\r\n        if i == 1 and d2 * 0.9 < diff:\r\n            linesV.append(min(xs) - d2 - diam / 2)\r\n            prev = 1\r\n        if d1 * 0.8 < diff < d1 * 1.2:\r\n            linesV.append(xs[i - 1] + diam + (d1 - diam) / 2)\r\n            prev = 1\r\n        elif d2 * 0.8 < diff < d2 * 1.1:\r\n            linesV.append(xs[i - 1] + diam + (d2 - diam) / 2)\r\n            prev = 0\r\n        elif d3 * 0.9 < diff < d3 * 1.1:\r\n            if prev == 1:\r\n                linesV.append(xs[i - 1] + diam + (d2 - diam) / 2)\r\n                linesV.append(xs[i - 1] + d2 + diam + (d1 - diam) / 2)\r\n            else:\r\n                linesV.append(xs[i - 1] + diam + (d1 - diam) / 2)\r\n                linesV.append(xs[i - 1] + d1 + diam + (d2 - diam) / 2)\r\n        elif d3 * 1.1 < diff:\r\n            if prev == 1:\r\n                linesV.append(xs[i - 1] + diam + (d2 - diam) / 2)\r\n                linesV.append(xs[i - 1] + d2 + diam + (d1 - diam) / 2)\r\n                linesV.append(xs[i - 1] + d3 + diam + (d2 - diam) / 2)\r\n                prev = 0\r\n            else:\r\n                linesV.append(xs[i - 1] + diam + (d1 - diam) / 2)\r\n                linesV.append(xs[i - 1] + d1 + diam + (d2 - diam) / 2)\r\n                linesV.append(xs[i - 1] + d1 + d2 + diam + (d1 - diam) / 2)\r\n                linesV.append(xs[i - 1] + d1 + d3 + diam + (d2 - diam) / 2)\r\n                prev = 1\r\n\r\n    linesV.append(max(xs) + diam * 1.5)\r\n    if len(linesV) % 2 == 0:\r\n        linesV.append(max(xs) + d2 + diam)\r\n\r\n    return linesV, d1, d2, d3, spacingX, spacingY\r\n\r\n\r\ndef get_letters(showID=False):\r\n    minYD = 0\r\n    Bxs = list(boundingBoxes)\r\n    Bxs.append((100000, 0))\r\n\r\n    dots = [[]]\r\n    for y in sorted(list(set(spacingY))):\r\n        if y > 1.3 * diam:\r\n            minYD = y * 1.5\r\n            break\r\n\r\n    # get lines of dots\r\n    for b in range(len(Bxs) - 1):\r\n        if Bxs[b][0] < Bxs[b + 1][0]:\r\n            if showID:\r\n                dots[-1].append((b, Bxs[b][0:2]))\r\n            else:\r\n                dots[-1].append(Bxs[b][0])\r\n        else:\r\n            if abs(Bxs[b + 1][1] - Bxs[b][1]) < minYD:\r\n                if showID:\r\n                    dots[-1].append((b, Bxs[b][0:2]))\r\n                else:\r\n                    dots[-1].append(Bxs[b][0])\r\n                dots.append([])\r\n            else:\r\n                if showID:\r\n                    dots[-1].append((b, Bxs[b][0:2]))\r\n                else:\r\n                    dots[-1].append(Bxs[b][0])\r\n                dots.append([])\r\n                if len(dots) % 3 == 0 and not dots[-1]:\r\n                    dots.append([])\r\n\r\n    letters = []\r\n    count = 0\r\n\r\n    for r in range(len(dots)):\r\n        if not dots[r]:\r\n            letters.append([0 for _ in range(len(linesV) - 1)])\r\n            continue\r\n\r\n        else:\r\n            letters.append([])\r\n            c = 0\r\n            i = 0\r\n            while i < len(linesV) - 1:\r\n                if c < len(dots[r]):\r\n                    if linesV[i] < dots[r][c] < linesV[i + 1]:\r\n                        letters[-1].append(1)\r\n                        c += 1\r\n                    else:\r\n                        letters[-1].append(0)\r\n                else:\r\n                    letters[-1].append(0)\r\n                i += 1\r\n\r\n    for l in range(len(letters)):\r\n        if l % 3 == 0: print()\r\n        print(letters[l])\r\n    print()\r\n\r\n    return letters\r\n\r\n\r\ndef translate(letters):\r\n    alpha = {'a': '1', 'b': '13', 'c': '12', 'd': '124', 'e': '14',\r\n             'f': '123', 'g': '1234', 'h': '134', 'i': '23', 'j': '234',\r\n             'k': '15', 'l': '135', 'm': '125', 'n': '1245', 'o': '145',\r\n             'p': '1235', 'q': '12345', 'r': '1345', 's': '235', 't': '2345',\r\n             'u': '156', 'v': '1356', 'w': '2346', 'x': '1256', 'y': '12456',\r\n             'z': '1456',\r\n             # special characters\r\n             '#': '2456', '^': '6', ',': '3', '.': '346',\r\n             '\\\"': '356', '^': '26', ':': '34', '\\'': '5'}\r\n\r\n    nums = {'a': '1', 'b': '2', 'c': '3', 'd': '4', 'e': '5', 'f': '6', 'g': '7', 'h': '8',\r\n            'i': '9', 'j': '0'}  # 2x2 braille letters\r\n\r\n    braille = {v: k for k, v in alpha.items()}\r\n    letters = np.array([np.array(l) for l in letters])\r\n    ans = ''\r\n\r\n    # printFig()              #test for gaussian blur (test2.jpg)\r\n\r\n    for r in range(0, len(letters), 3):\r\n        for c in range(0, len(letters[0]), 2):\r\n            f = letters[r:r + 3, c:c + 2].flatten()\r\n            f = ''.join([str(i + 1) for i, d in enumerate(f) if d == 1])\r\n            if f == '6': f = '26'\r\n            if not f:\r\n                if ans[-1] != ' ': ans += ' '\r\n            elif f in braille.keys():\r\n                ans += braille[f]\r\n            else:\r\n                ans += '?'\r\n        if ans[-1] != ' ': ans += ' '\r\n\r\n    def replace_nums(m):  # replace numbers\r\n        return nums.get(m.group('key'), m.group(0))\r\n\r\n    ans = re.sub('#(?P<key>[a-zA-Z])', replace_nums, ans)\r\n\r\n    def capitalize(m):  # capitalize\r\n        return m.group(0).upper()[1]\r\n\r\n    ans = re.sub('\\^(?P<key>[a-zA-Z])', capitalize, ans)\r\n\r\n    return ans\r\n\r\n\r\ndef printFig():  # shows the image processing steps\r\n    fig, axarr = plt.subplots(3, 2)\r\n    fig.suptitle('Image Processing')\r\n    axarr[0, 0].imshow(image)  # original image\r\n    axarr[0, 0].set_title(\"Original Image\")\r\n    axarr[0, 0].axis('off')\r\n\r\n    axarr[0, 1].imshow(gray)  # greyscales image\r\n    axarr[0, 1].set_title(\"Grayscale\")\r\n    axarr[0, 1].axis('off')\r\n\r\n    axarr[1, 0].imshow(edged)  # checks for areas of interest\r\n    axarr[1, 0].set_title(\"Edging\")\r\n    axarr[1, 0].axis('off')\r\n\r\n    axarr[1, 1].set_title(\"Contours\")  # shows the contours of the alignments\r\n    axarr[1, 1].imshow(image)\r\n    for x in linesV:\r\n        axarr[1, 1].axvline(x)\r\n    axarr[1, 1].axis('off')\r\n\r\n    axarr[2, 0].imshow(paper)  # counts the dots in an array\r\n    axarr[2, 0].set_title(\"Sorting Array\")\r\n    axarr[2, 0].axis('off')\r\n\r\n    axarr[2, 1].imshow(thresh)  # adds blur to remove unnecessary noise\r\n    axarr[2, 1].set_title(\"Gaussian Bluring\")\r\n    axarr[2, 1].axis('off')\r\n    plt.show()\r\n\r\n    io.imshow(thresh)  # final image\r\n    plt.title('Final Image')\r\n    plt.axis('off')\r\n    plt.show()\r\n\r\n\r\n# -----------------------MAIN------------------------- #\r\n\r\nimage, ctrs, paper, gray, edged, thresh = get_image(FILEPATH, iter=0, width=1500)  # processes image\r\n\r\ndiam = get_diameter()  # shows the area of interest for the computer\r\ndotCtrs = get_circles()\r\n\r\nquestionCtrs, boundingBoxes, xs, ys = sort_contours(dotCtrs)  # counts dot array\r\ndraw_contours(questionCtrs)  # contours image\r\n\r\nlinesV, d1, d2, d3, spacingX, spacingY = get_spacing()  # gets spacing lines\r\nletters = get_letters()  # translates braille\r\n\r\nprint(translate(letters))  # print the translated braille\r\nprintFig()           #prints the image processing steps\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/src/main/python/brailleProcessingLib.py	(revision 48db88dd91de92680b233372650d3a88afb977cf)
+++ app/src/main/python/brailleProcessingLib.py	(date 1605233415396)
@@ -1,5 +1,3 @@
-from imutils.perspective import four_point_transform as FPT
-from imutils import contours
 from collections import Counter  # counter
 from skimage import io  # library to read images
 import matplotlib.pyplot as plt  # library to show image to user
@@ -8,30 +6,32 @@
 import cv2  # advanced for image processing
 import re  # regex
 
-FILEPATH = 'test.jpg'
 
-
+FILEPATH = "/storage/emulated/0/DCIM/Braille/test.jpg"
 # test for alphabet translation / iter = 0 (test.jpg)
 # test for gaussian blur on nemmeth example / iter >= 3 (test2.jpg)
 
+
 # -----------------------FUNCTIONS------------------------- #
 
+
+def helloworld():
+    return "Hello World!"
+
+
 def get_image(FILEPATH, iter=2, width=None):
     image = io.imread(FILEPATH)  # reads the url and opens the temporary image to user
 
     if width:
-        image = imutils.resize(image, width)  # resizes the image per the restricted width
-    ans = image.copy()  # create a copy backup image
+        image = imutils.resize(image, width)  # resized the image per the restricted width
 
-    # image procesesing
+    # image processing
     accumEdged = np.zeros(image.shape[:2], dtype="uint8")
-    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # convert image to black and white
-    blurred = cv2.GaussianBlur(gray, (5, 5), 0)  # blur to remove some of the noise
+    grey = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # convert image to black and white
+    blurred = cv2.GaussianBlur(grey, (5, 5), 0)  # blur to remove some of the noise
     edged = cv2.Canny(blurred, 75, 200)  # get edges(converts image to easy detectable dots)
-    accumEdged = cv2.bitwise_or(accumEdged, edged)
-    ctrs = imutils.grab_contours(cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL,
-                                                  cv2.CHAIN_APPROX_SIMPLE))  # get contours(increases accuracy)
-    docCnt = None
+    cv2.bitwise_or(accumEdged, edged)
+    ctrs = imutils.grab_contours(cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE))  # get contours(increases accuracy)
 
     # ensure that at least one contour was found to know an image can be processed
     if len(ctrs) > 0:  # sort the contours according to their size in descending order
@@ -43,23 +43,22 @@
 
             # if our approximated contour has four points, then we can assume we have found the image
             if len(approx) == 4:
-                docCnt = approx
                 break
     paper = image.copy()  # creates a copy of the processed image
 
-    # apply Otsu's thresholding method to binarize the image
-    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]
+    # apply Otsu's threshold method to binary the image
+    thresh = cv2.threshold(grey, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]
     kernel = np.ones((5, 5), np.uint8)
 
     # erode and dilate to remove some of the unnecessary detail
     thresh = cv2.erode(thresh, kernel, iterations=iter)
     thresh = cv2.dilate(thresh, kernel, iterations=iter)
 
-    # find contours in the thresholded image
+    # find contours in the threshold's image
     ctrs = imutils.grab_contours(
         cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE))
 
-    return image, ctrs, paper, gray, edged, thresh
+    return image, ctrs, paper, grey, edged, thresh
 
 
 def get_diameter():  # shows the area of interest for the computer
@@ -135,10 +134,8 @@
     spacingX = spacing(0)
     spacingY = spacing(1)
 
-    # smallest x-seperation (between two adjacent dots in a letter)
-    m = min(spacingX)
-
-    c = 0
+    # smallest x-separation (between two adjacent dots in a letter)
+    min(spacingX)
 
     d1 = spacingX[0]
     d2 = 0
@@ -229,7 +226,6 @@
                     dots.append([])
 
     letters = []
-    count = 0
 
     for r in range(len(dots)):
         if not dots[r]:
@@ -251,9 +247,9 @@
                     letters[-1].append(0)
                 i += 1
 
-    for l in range(len(letters)):
-        if l % 3 == 0: print()
-        print(letters[l])
+    for x in range(len(letters)):
+        if x % 3 == 0: print()
+        print(letters[x])
     print()
 
     return letters
@@ -267,14 +263,13 @@
              'u': '156', 'v': '1356', 'w': '2346', 'x': '1256', 'y': '12456',
              'z': '1456',
              # special characters
-             '#': '2456', '^': '6', ',': '3', '.': '346',
+             '#': '2456', ',': '3', '.': '346',
              '\"': '356', '^': '26', ':': '34', '\'': '5'}
 
-    nums = {'a': '1', 'b': '2', 'c': '3', 'd': '4', 'e': '5', 'f': '6', 'g': '7', 'h': '8',
-            'i': '9', 'j': '0'}  # 2x2 braille letters
+    nums = {'a': '1', 'b': '2', 'c': '3', 'd': '4', 'e': '5', 'f': '6', 'g': '7', 'h': '8', 'i': '9', 'j': '0'}  # 2x2 braille letters
 
     braille = {v: k for k, v in alpha.items()}
-    letters = np.array([np.array(l) for l in letters])
+    letters = np.array([np.array(x) for x in letters])
     ans = ''
 
     # printFig()              #test for gaussian blur (test2.jpg)
@@ -306,14 +301,14 @@
 
 
 def printFig():  # shows the image processing steps
-    fig, axarr = plt.subplots(3, 2)
+    fig, axarr = plt.subplots(4, 2)
     fig.suptitle('Image Processing')
     axarr[0, 0].imshow(image)  # original image
     axarr[0, 0].set_title("Original Image")
     axarr[0, 0].axis('off')
 
-    axarr[0, 1].imshow(gray)  # greyscales image
-    axarr[0, 1].set_title("Grayscale")
+    axarr[0, 1].imshow(gray)  # greyscale image
+    axarr[0, 1].set_title("Greyscale")
     axarr[0, 1].axis('off')
 
     axarr[1, 0].imshow(edged)  # checks for areas of interest
@@ -331,11 +326,16 @@
     axarr[2, 0].axis('off')
 
     axarr[2, 1].imshow(thresh)  # adds blur to remove unnecessary noise
-    axarr[2, 1].set_title("Gaussian Bluring")
+    axarr[2, 1].set_title("Gaussian Blurring")
     axarr[2, 1].axis('off')
     plt.show()
 
-    io.imshow(thresh)  # final image
+    axarr[3, 0].imshow(image)  # for comparison
+    axarr[3, 0].set_title("Original Image")
+    axarr[3, 0].axis('off')
+    plt.show()
+
+    io.imshow(thresh)
     plt.title('Final Image')
     plt.axis('off')
     plt.show()
@@ -343,6 +343,7 @@
 
 # -----------------------MAIN------------------------- #
 
+
 image, ctrs, paper, gray, edged, thresh = get_image(FILEPATH, iter=0, width=1500)  # processes image
 
 diam = get_diameter()  # shows the area of interest for the computer
@@ -355,4 +356,4 @@
 letters = get_letters()  # translates braille
 
 print(translate(letters))  # print the translated braille
-printFig()           #prints the image processing steps
+printFig()  # prints the image processing steps
Index: app/src/main/python/test.py
===================================================================
--- app/src/main/python/test.py	(revision 48db88dd91de92680b233372650d3a88afb977cf)
+++ app/src/main/python/test.py	(revision 48db88dd91de92680b233372650d3a88afb977cf)
@@ -1,2 +0,0 @@
-def helloworld():
-    return "Hello World from Chaquopy!"
Index: app/src/main/java/com/example/braille2text/CameraActivity.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>package com.example.braille2text;\r\n\r\nimport android.Manifest;\r\nimport android.content.Context;\r\nimport android.content.pm.PackageManager;\r\nimport android.graphics.ImageFormat;\r\nimport android.graphics.SurfaceTexture;\r\nimport android.hardware.camera2.CameraAccessException;\r\nimport android.hardware.camera2.CameraCaptureSession;\r\nimport android.hardware.camera2.CameraCharacteristics;\r\nimport android.hardware.camera2.CameraDevice;\r\nimport android.hardware.camera2.CameraManager;\r\nimport android.hardware.camera2.CameraMetadata;\r\nimport android.hardware.camera2.CaptureRequest;\r\nimport android.hardware.camera2.TotalCaptureResult;\r\nimport android.hardware.camera2.params.StreamConfigurationMap;\r\nimport android.media.Image;\r\nimport android.media.ImageReader;\r\nimport android.os.Bundle;\r\nimport android.os.Environment;\r\nimport android.os.Handler;\r\nimport android.os.HandlerThread;\r\n\r\nimport android.util.Log;\r\nimport android.util.Size;\r\nimport android.util.SparseIntArray;\r\nimport android.view.Surface;\r\nimport android.view.TextureView;\r\nimport android.view.View;\r\nimport android.widget.Button;\r\nimport android.widget.Toast;\r\n\r\nimport androidx.annotation.NonNull;\r\nimport androidx.appcompat.app.AppCompatActivity;\r\nimport androidx.core.app.ActivityCompat;\r\n\r\nimport java.io.File;\r\nimport java.io.FileNotFoundException;\r\nimport java.io.FileOutputStream;\r\nimport java.io.IOException;\r\nimport java.io.OutputStream;\r\nimport java.nio.ByteBuffer;\r\nimport java.text.SimpleDateFormat;\r\nimport java.util.ArrayList;\r\nimport java.util.Arrays;\r\nimport java.util.Date;\r\nimport java.util.List;\r\npublic class CameraActivity extends AppCompatActivity {\r\n    private static final String TAG = \"AndroidCameraApi\";\r\n    private Button takePictureButton;\r\n    private TextureView textureView;\r\n    private static final SparseIntArray ORIENTATIONS = new SparseIntArray();\r\n    static {\r\n        ORIENTATIONS.append(Surface.ROTATION_0, 90);\r\n        ORIENTATIONS.append(Surface.ROTATION_90, 0);\r\n        ORIENTATIONS.append(Surface.ROTATION_180, 270);\r\n        ORIENTATIONS.append(Surface.ROTATION_270, 180);\r\n    }\r\n    private String cameraId;\r\n    protected CameraDevice cameraDevice;\r\n    protected CameraCaptureSession cameraCaptureSessions;\r\n    protected CaptureRequest captureRequest;\r\n    protected CaptureRequest.Builder captureRequestBuilder;\r\n    private Size imageDimension;\r\n    private ImageReader imageReader;\r\n    private File file;\r\n    private static final int REQUEST_CAMERA_PERMISSION = 200;\r\n    private boolean mFlashSupported;\r\n    private Handler mBackgroundHandler;\r\n    private HandlerThread mBackgroundThread;\r\n    @Override\r\n    protected void onCreate(Bundle savedInstanceState) {\r\n        super.onCreate(savedInstanceState);\r\n        setContentView(R.layout.activity_camera);\r\n        textureView = (TextureView) findViewById(R.id.texture);\r\n        assert textureView != null;\r\n        textureView.setSurfaceTextureListener(textureListener);\r\n        takePictureButton = (Button) findViewById(R.id.btn_takepicture);\r\n        assert takePictureButton != null;\r\n        takePictureButton.setOnClickListener(new View.OnClickListener() {\r\n            @Override\r\n            public void onClick(View v) {\r\n                takePicture();\r\n            }\r\n        });\r\n    }\r\n    TextureView.SurfaceTextureListener textureListener = new TextureView.SurfaceTextureListener() {\r\n        @Override\r\n        public void onSurfaceTextureAvailable(SurfaceTexture surface, int width, int height) {\r\n            //open your camera here\r\n            openCamera();\r\n        }\r\n        @Override\r\n        public void onSurfaceTextureSizeChanged(SurfaceTexture surface, int width, int height) {\r\n            // Transform you image captured size according to the surface width and height\r\n        }\r\n        @Override\r\n        public boolean onSurfaceTextureDestroyed(SurfaceTexture surface) {\r\n            return false;\r\n        }\r\n        @Override\r\n        public void onSurfaceTextureUpdated(SurfaceTexture surface) {\r\n        }\r\n    };\r\n    private final CameraDevice.StateCallback stateCallback = new CameraDevice.StateCallback() {\r\n        @Override\r\n        public void onOpened(CameraDevice camera) {\r\n            //This is called when the camera is open\r\n            Log.e(TAG, \"onOpened\");\r\n            cameraDevice = camera;\r\n            createCameraPreview();\r\n        }\r\n        @Override\r\n        public void onDisconnected(CameraDevice camera) {\r\n            cameraDevice.close();\r\n        }\r\n        @Override\r\n        public void onError(CameraDevice camera, int error) {\r\n            cameraDevice.close();\r\n            cameraDevice = null;\r\n        }\r\n    };\r\n    final CameraCaptureSession.CaptureCallback captureCallbackListener = new CameraCaptureSession.CaptureCallback() {\r\n        @Override\r\n        public void onCaptureCompleted(CameraCaptureSession session, CaptureRequest request, TotalCaptureResult result) {\r\n            super.onCaptureCompleted(session, request, result);\r\n            Toast.makeText(CameraActivity.this, \"Saved:\" + file, Toast.LENGTH_SHORT).show();\r\n            createCameraPreview();\r\n        }\r\n    };\r\n    protected void startBackgroundThread() {\r\n        mBackgroundThread = new HandlerThread(\"Camera Background\");\r\n        mBackgroundThread.start();\r\n        mBackgroundHandler = new Handler(mBackgroundThread.getLooper());\r\n    }\r\n    protected void stopBackgroundThread() {\r\n        mBackgroundThread.quitSafely();\r\n        try {\r\n            mBackgroundThread.join();\r\n            mBackgroundThread = null;\r\n            mBackgroundHandler = null;\r\n        } catch (InterruptedException e) {\r\n            e.printStackTrace();\r\n        }\r\n    }\r\n    protected void takePicture() {\r\n        if(null == cameraDevice) {\r\n            Log.e(TAG, \"cameraDevice is null\");\r\n            return;\r\n        }\r\n        CameraManager manager = (CameraManager) getSystemService(Context.CAMERA_SERVICE);\r\n        try {\r\n            CameraCharacteristics characteristics = manager.getCameraCharacteristics(cameraDevice.getId());\r\n            Size[] jpegSizes = null;\r\n            if (characteristics != null) {\r\n                jpegSizes = characteristics.get(CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP).getOutputSizes(ImageFormat.JPEG);\r\n            }\r\n            int width = 640;\r\n            int height = 480;\r\n            if (jpegSizes != null && 0 < jpegSizes.length) {\r\n                width = jpegSizes[0].getWidth();\r\n                height = jpegSizes[0].getHeight();\r\n            }\r\n            ImageReader reader = ImageReader.newInstance(width, height, ImageFormat.JPEG, 1);\r\n            List<Surface> outputSurfaces = new ArrayList<Surface>(2);\r\n            outputSurfaces.add(reader.getSurface());\r\n            outputSurfaces.add(new Surface(textureView.getSurfaceTexture()));\r\n            final CaptureRequest.Builder captureBuilder = cameraDevice.createCaptureRequest(CameraDevice.TEMPLATE_STILL_CAPTURE);\r\n            captureBuilder.addTarget(reader.getSurface());\r\n            captureBuilder.set(CaptureRequest.CONTROL_MODE, CameraMetadata.CONTROL_MODE_AUTO);\r\n            // Orientation\r\n            int rotation = getWindowManager().getDefaultDisplay().getRotation();\r\n            captureBuilder.set(CaptureRequest.JPEG_ORIENTATION, ORIENTATIONS.get(rotation));\r\n\r\n            //creating file name\r\n            String timestamp = new SimpleDateFormat(\"yyyyMMdd_HHmmss\").format(new Date());\r\n            String prepend = \"BRAILLE_\" + timestamp + \".jpg\";\r\n\r\n            //Creating folder for braille files\r\n            File folder = new File(Environment.getExternalStorageDirectory()+\"/DCIM/Braille\");\r\n\r\n            if(!folder.exists()) {\r\n                folder.mkdir();\r\n            }\r\n\r\n            final File file = new File(Environment.getExternalStorageDirectory()+\"/DCIM/Braille/\"+prepend);\r\n            ImageReader.OnImageAvailableListener readerListener = new ImageReader.OnImageAvailableListener() {\r\n                @Override\r\n                public void onImageAvailable(ImageReader reader) {\r\n                    Image image = null;\r\n                    try {\r\n                        image = reader.acquireLatestImage();\r\n                        ByteBuffer buffer = image.getPlanes()[0].getBuffer();\r\n                        byte[] bytes = new byte[buffer.capacity()];\r\n                        buffer.get(bytes);\r\n                        save(bytes);\r\n                    } catch (FileNotFoundException e) {\r\n                        e.printStackTrace();\r\n                    } catch (IOException e) {\r\n                        e.printStackTrace();\r\n                    } finally {\r\n                        if (image != null) {\r\n                            image.close();\r\n                        }\r\n                    }\r\n                }\r\n                private void save(byte[] bytes) throws IOException {\r\n                    OutputStream output = null;\r\n                    try {\r\n                        output = new FileOutputStream(file);\r\n                        output.write(bytes);\r\n                    } finally {\r\n                        if (null != output) {\r\n                            output.close();\r\n                        }\r\n                    }\r\n                }\r\n            };\r\n            reader.setOnImageAvailableListener(readerListener, mBackgroundHandler);\r\n            final CameraCaptureSession.CaptureCallback captureListener = new CameraCaptureSession.CaptureCallback() {\r\n                @Override\r\n                public void onCaptureCompleted(CameraCaptureSession session, CaptureRequest request, TotalCaptureResult result) {\r\n                    super.onCaptureCompleted(session, request, result);\r\n                    Toast.makeText(CameraActivity.this, \"Saved:\" + file, Toast.LENGTH_SHORT).show();\r\n                    createCameraPreview();\r\n                }\r\n            };\r\n            cameraDevice.createCaptureSession(outputSurfaces, new CameraCaptureSession.StateCallback() {\r\n                @Override\r\n                public void onConfigured(CameraCaptureSession session) {\r\n                    try {\r\n                        session.capture(captureBuilder.build(), captureListener, mBackgroundHandler);\r\n                    } catch (CameraAccessException e) {\r\n                        e.printStackTrace();\r\n                    }\r\n                }\r\n                @Override\r\n                public void onConfigureFailed(CameraCaptureSession session) {\r\n                }\r\n            }, mBackgroundHandler);\r\n        } catch (CameraAccessException e) {\r\n            e.printStackTrace();\r\n        }\r\n    }\r\n    protected void createCameraPreview() {\r\n        try {\r\n            SurfaceTexture texture = textureView.getSurfaceTexture();\r\n            assert texture != null;\r\n            texture.setDefaultBufferSize(imageDimension.getWidth(), imageDimension.getHeight());\r\n            Surface surface = new Surface(texture);\r\n            captureRequestBuilder = cameraDevice.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);\r\n            captureRequestBuilder.addTarget(surface);\r\n            cameraDevice.createCaptureSession(Arrays.asList(surface), new CameraCaptureSession.StateCallback(){\r\n                @Override\r\n                public void onConfigured(@NonNull CameraCaptureSession cameraCaptureSession) {\r\n                    //The camera is already closed\r\n                    if (null == cameraDevice) {\r\n                        return;\r\n                    }\r\n                    // When the session is ready, we start displaying the preview.\r\n                    cameraCaptureSessions = cameraCaptureSession;\r\n                    updatePreview();\r\n                }\r\n                @Override\r\n                public void onConfigureFailed(@NonNull CameraCaptureSession cameraCaptureSession) {\r\n                    Toast.makeText(CameraActivity.this, \"Configuration change\", Toast.LENGTH_SHORT).show();\r\n                }\r\n            }, null);\r\n        } catch (CameraAccessException e) {\r\n            e.printStackTrace();\r\n        }\r\n    }\r\n    private void openCamera() {\r\n        CameraManager manager = (CameraManager) getSystemService(Context.CAMERA_SERVICE);\r\n        Log.e(TAG, \"is camera open\");\r\n        try {\r\n            cameraId = manager.getCameraIdList()[0];\r\n            CameraCharacteristics characteristics = manager.getCameraCharacteristics(cameraId);\r\n            StreamConfigurationMap map = characteristics.get(CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);\r\n            assert map != null;\r\n            imageDimension = map.getOutputSizes(SurfaceTexture.class)[0];\r\n            // Add permission for camera and let user grant the permission\r\n            if (ActivityCompat.checkSelfPermission(this, Manifest.permission.CAMERA) != PackageManager.PERMISSION_GRANTED && ActivityCompat.checkSelfPermission(this, Manifest.permission.WRITE_EXTERNAL_STORAGE) != PackageManager.PERMISSION_GRANTED) {\r\n                ActivityCompat.requestPermissions(CameraActivity.this, new String[]{Manifest.permission.CAMERA, Manifest.permission.WRITE_EXTERNAL_STORAGE}, REQUEST_CAMERA_PERMISSION);\r\n                return;\r\n            }\r\n            manager.openCamera(cameraId, stateCallback, null);\r\n        } catch (CameraAccessException e) {\r\n            e.printStackTrace();\r\n        }\r\n        Log.e(TAG, \"openCamera X\");\r\n    }\r\n    protected void updatePreview() {\r\n        if(null == cameraDevice) {\r\n            Log.e(TAG, \"updatePreview error, return\");\r\n        }\r\n        captureRequestBuilder.set(CaptureRequest.CONTROL_MODE, CameraMetadata.CONTROL_MODE_AUTO);\r\n        try {\r\n            cameraCaptureSessions.setRepeatingRequest(captureRequestBuilder.build(), null, mBackgroundHandler);\r\n        } catch (CameraAccessException e) {\r\n            e.printStackTrace();\r\n        }\r\n    }\r\n    private void closeCamera() {\r\n        if (null != cameraDevice) {\r\n            cameraDevice.close();\r\n            cameraDevice = null;\r\n        }\r\n        if (null != imageReader) {\r\n            imageReader.close();\r\n            imageReader = null;\r\n        }\r\n    }\r\n    @Override\r\n    public void onRequestPermissionsResult(int requestCode, @NonNull String[] permissions, @NonNull int[] grantResults) {\r\n        if (requestCode == REQUEST_CAMERA_PERMISSION) {\r\n            if (grantResults[0] == PackageManager.PERMISSION_DENIED) {\r\n                // close the app\r\n                Toast.makeText(CameraActivity.this, \"Sorry!!!, you can't use this app without granting permission\", Toast.LENGTH_LONG).show();\r\n                finish();\r\n            }\r\n        }\r\n    }\r\n    @Override\r\n    protected void onResume() {\r\n        super.onResume();\r\n        Log.e(TAG, \"onResume\");\r\n        startBackgroundThread();\r\n        if (textureView.isAvailable()) {\r\n            openCamera();\r\n        } else {\r\n            textureView.setSurfaceTextureListener(textureListener);\r\n        }\r\n    }\r\n    @Override\r\n    protected void onPause() {\r\n        Log.e(TAG, \"onPause\");\r\n        //closeCamera();\r\n        stopBackgroundThread();\r\n        super.onPause();\r\n    }\r\n\r\n}
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/src/main/java/com/example/braille2text/CameraActivity.java	(revision 48db88dd91de92680b233372650d3a88afb977cf)
+++ app/src/main/java/com/example/braille2text/CameraActivity.java	(date 1605238577247)
@@ -2,6 +2,7 @@
 
 import android.Manifest;
 import android.content.Context;
+import android.content.Intent;
 import android.content.pm.PackageManager;
 import android.graphics.ImageFormat;
 import android.graphics.SurfaceTexture;
@@ -194,6 +195,7 @@
                         byte[] bytes = new byte[buffer.capacity()];
                         buffer.get(bytes);
                         save(bytes);
+
                     } catch (FileNotFoundException e) {
                         e.printStackTrace();
                     } catch (IOException e) {
Index: app/src/main/res/layout/activity_image_processing.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/src/main/res/layout/activity_image_processing.xml	(date 1605238214605)
+++ app/src/main/res/layout/activity_image_processing.xml	(date 1605238214605)
@@ -0,0 +1,21 @@
+<?xml version="1.0" encoding="utf-8"?>
+<androidx.constraintlayout.widget.ConstraintLayout xmlns:android="http://schemas.android.com/apk/res/android"
+    xmlns:app="http://schemas.android.com/apk/res-auto"
+    xmlns:tools="http://schemas.android.com/tools"
+    android:layout_width="match_parent"
+    android:layout_height="match_parent"
+    tools:context=".ImageProcessing">
+
+    <TextView
+        android:layout_width="wrap_content"
+        android:layout_height="wrap_content"
+        android:layout_alignParentTop="true"
+        android:layout_centerHorizontal="true"
+        android:id="@+id/txtPythonShow"
+        android:textColor="#F44336"
+        android:textSize="30sp"
+        app:layout_constraintEnd_toEndOf="parent"
+        app:layout_constraintStart_toStartOf="parent"
+        tools:layout_editor_absoluteY="198dp" />
+
+</androidx.constraintlayout.widget.ConstraintLayout>
\ No newline at end of file
Index: app/src/main/res/values/themes.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/src/main/res/values/themes.xml	(date 1605236482149)
+++ app/src/main/res/values/themes.xml	(date 1605236482149)
@@ -0,0 +1,11 @@
+<resources>
+
+    <style name="AppTheme.NoActionBar">
+        <item name="windowActionBar">false</item>
+        <item name="windowNoTitle">true</item>
+    </style>
+
+    <style name="AppTheme.AppBarOverlay" parent="ThemeOverlay.AppCompat.Dark.ActionBar" />
+
+    <style name="AppTheme.PopupOverlay" parent="ThemeOverlay.AppCompat.Light" />
+</resources>
\ No newline at end of file
Index: app/src/main/res/values/dimens.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/src/main/res/values/dimens.xml	(date 1605236480401)
+++ app/src/main/res/values/dimens.xml	(date 1605236480401)
@@ -0,0 +1,7 @@
+<?xml version="1.0" encoding="utf-8"?>
+<resources>
+    <dimen name="fab_margin">16dp</dimen>
+    <dimen name="app_bar_height">200dp</dimen>
+    <dimen name="item_width">200dp</dimen>
+    <dimen name="text_margin">16dp</dimen>
+</resources>
\ No newline at end of file
Index: app/build.gradle
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>apply plugin: 'com.android.application'\r\napply plugin: 'kotlin-android'\r\napply plugin: 'kotlin-android-extensions'\r\napply plugin: 'com.chaquo.python'\r\n\r\nandroid {\r\n    compileSdkVersion 29\r\n    buildToolsVersion \"29.0.3\"\r\n\r\n    defaultConfig {\r\n        applicationId \"com.example.braille2text\"\r\n        minSdkVersion 29\r\n        targetSdkVersion 29\r\n        versionCode 1\r\n        versionName \"1.0\"\r\n\r\n        python{\r\n            pip{\r\n                install \"matplotlib\"\r\n                install \"scikit-image\"\r\n                install \"numpy\"\r\n                install \"imutils\"\r\n                install \"opencv-contrib-python\"\r\n            }\r\n        }\r\n\r\n        sourceSets {\r\n            main {\r\n                python {\r\n                    srcDirs = [\"src/main/python\"]\r\n                }\r\n            }\r\n        }\r\n        python {\r\n            buildPython \"C:/Users/Koolk/AppData/Local/Programs/Python/Python38-32/python.exe\"\r\n        }\r\n        ndk {\r\n            abiFilters \"armeabi-v7a\", \"x86\"\r\n        }\r\n\r\n        testInstrumentationRunner \"androidx.test.runner.AndroidJUnitRunner\"\r\n    }\r\n\r\n    buildTypes {\r\n        release {\r\n            minifyEnabled false\r\n            proguardFiles getDefaultProguardFile('proguard-android-optimize.txt'), 'proguard-rules.pro'\r\n        }\r\n    }\r\n}\r\n\r\ndependencies {\r\n    implementation fileTree(dir: \"libs\", include: [\"*.jar\"])\r\n    implementation 'androidx.appcompat:appcompat:1.2.0'\r\n    implementation 'androidx.constraintlayout:constraintlayout:2.0.4'\r\n    implementation project(path: ':openCVLibrary343')\r\n    testImplementation 'junit:junit:4.13.1'\r\n    androidTestImplementation 'androidx.test.ext:junit:1.1.2'\r\n    androidTestImplementation 'androidx.test.espresso:espresso-core:3.3.0'\r\n    implementation 'androidx.core:core-ktx:1.5.0-alpha05'\r\n    implementation \"org.jetbrains.kotlin:kotlin-stdlib-jdk7:$kotlin_version\"\r\n}\r\nrepositories {\r\n    mavenCentral()\r\n}
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/build.gradle	(revision 48db88dd91de92680b233372650d3a88afb977cf)
+++ app/build.gradle	(date 1605236481623)
@@ -54,6 +54,8 @@
     implementation 'androidx.appcompat:appcompat:1.2.0'
     implementation 'androidx.constraintlayout:constraintlayout:2.0.4'
     implementation project(path: ':openCVLibrary343')
+    implementation 'androidx.recyclerview:recyclerview:1.1.0'
+    implementation 'com.google.android.material:material:1.1.0'
     testImplementation 'junit:junit:4.13.1'
     androidTestImplementation 'androidx.test.ext:junit:1.1.2'
     androidTestImplementation 'androidx.test.espresso:espresso-core:3.3.0'
Index: app/src/main/AndroidManifest.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"utf-8\"?>\r\n<manifest xmlns:android=\"http://schemas.android.com/apk/res/android\"\r\n    package=\"com.example.braille2text\">\r\n\r\n    <uses-permission android:name=\"android.permission.CAMERA\" />\r\n    <uses-permission android:name=\"android.permission.WRITE_EXTERNAL_STORAGE\" />\r\n    <uses-feature android:name=\"android.hardware.camera2\" />\r\n\r\n\r\n    <application\r\n        android:name = \".ImageProcessing\"\r\n        android:allowBackup=\"true\"\r\n        android:icon=\"@mipmap/ic_launcher\"\r\n        android:requestLegacyExternalStorage=\"true\"\r\n        android:label=\"@string/app_name\"\r\n        android:roundIcon=\"@mipmap/ic_launcher_round\"\r\n        android:supportsRtl=\"true\"\r\n        android:theme=\"@style/AppTheme\">\r\n        <activity android:name=\".CameraActivity\"></activity>\r\n        <activity android:name=\".MainActivity\">\r\n            <intent-filter>\r\n                <action android:name=\"android.intent.action.MAIN\" />\r\n\r\n                <category android:name=\"android.intent.category.LAUNCHER\" />\r\n            </intent-filter>\r\n        </activity>\r\n    </application>\r\n\r\n</manifest>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/src/main/AndroidManifest.xml	(revision 48db88dd91de92680b233372650d3a88afb977cf)
+++ app/src/main/AndroidManifest.xml	(date 1605238390735)
@@ -4,19 +4,37 @@
 
     <uses-permission android:name="android.permission.CAMERA" />
     <uses-permission android:name="android.permission.WRITE_EXTERNAL_STORAGE" />
+    <uses-permission android:name="android.permission.READ_EXTERNAL_STORAGE" />
+
     <uses-feature android:name="android.hardware.camera2" />
 
-
     <application
-        android:name = ".ImageProcessing"
+        android:name=".ImageProcessing"
         android:allowBackup="true"
         android:icon="@mipmap/ic_launcher"
-        android:requestLegacyExternalStorage="true"
         android:label="@string/app_name"
+        android:requestLegacyExternalStorage="true"
         android:roundIcon="@mipmap/ic_launcher_round"
         android:supportsRtl="true"
         android:theme="@style/AppTheme">
-        <activity android:name=".CameraActivity"></activity>
+        <activity android:name=".MainActivity2"></activity>
+        <activity android:name=".ImageProcessing" />
+        <activity android:name=".ImageProcessing\" />
+        <activity android:name=".ImageProcessings" />
+        <activity
+            android:name=".ItemListActivity"
+            android:label="@string/title_item_list"
+            android:theme="@style/AppTheme.NoActionBar" />
+        <activity
+            android:name=".ItemDetailActivity"
+            android:label="@string/title_item_detail"
+            android:parentActivityName=".ItemListActivity"
+            android:theme="@style/AppTheme.NoActionBar">
+            <meta-data
+                android:name="android.support.PARENT_ACTIVITY"
+                android:value="com.example.braille2text.ItemListActivity" />
+        </activity>
+        <activity android:name=".CameraActivity" />
         <activity android:name=".MainActivity">
             <intent-filter>
                 <action android:name="android.intent.action.MAIN" />
Index: .idea/inspectionProfiles/Project_Default.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><component name=\"InspectionProjectProfileManager\">\r\n  <profile version=\"1.0\">\r\n    <option name=\"myName\" value=\"Project Default\" />\r\n    <inspection_tool class=\"ConstantConditions\" enabled=\"true\" level=\"WARNING\" enabled_by_default=\"true\">\r\n      <option name=\"SUGGEST_NULLABLE_ANNOTATIONS\" value=\"false\" />\r\n      <option name=\"DONT_REPORT_TRUE_ASSERT_STATEMENTS\" value=\"false\" />\r\n    </inspection_tool>\r\n    <inspection_tool class=\"PyPep8Inspection\" enabled=\"true\" level=\"WEAK WARNING\" enabled_by_default=\"true\">\r\n      <option name=\"ignoredErrors\">\r\n        <list>\r\n          <option value=\"E701\" />\r\n        </list>\r\n      </option>\r\n    </inspection_tool>\r\n    <inspection_tool class=\"PyPep8NamingInspection\" enabled=\"true\" level=\"WEAK WARNING\" enabled_by_default=\"true\">\r\n      <option name=\"ignoredErrors\">\r\n        <list>\r\n          <option value=\"N803\" />\r\n          <option value=\"N802\" />\r\n          <option value=\"N806\" />\r\n          <option value=\"N812\" />\r\n        </list>\r\n      </option>\r\n    </inspection_tool>\r\n  </profile>\r\n</component>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- .idea/inspectionProfiles/Project_Default.xml	(revision 48db88dd91de92680b233372650d3a88afb977cf)
+++ .idea/inspectionProfiles/Project_Default.xml	(date 1605225334513)
@@ -1,14 +1,12 @@
 <component name="InspectionProjectProfileManager">
   <profile version="1.0">
     <option name="myName" value="Project Default" />
-    <inspection_tool class="ConstantConditions" enabled="true" level="WARNING" enabled_by_default="true">
-      <option name="SUGGEST_NULLABLE_ANNOTATIONS" value="false" />
-      <option name="DONT_REPORT_TRUE_ASSERT_STATEMENTS" value="false" />
-    </inspection_tool>
     <inspection_tool class="PyPep8Inspection" enabled="true" level="WEAK WARNING" enabled_by_default="true">
       <option name="ignoredErrors">
         <list>
           <option value="E701" />
+          <option value="E501" />
+          <option value="E402" />
         </list>
       </option>
     </inspection_tool>
@@ -19,6 +17,27 @@
           <option value="N802" />
           <option value="N806" />
           <option value="N812" />
+        </list>
+      </option>
+    </inspection_tool>
+    <inspection_tool class="PyShadowingBuiltinsInspection" enabled="true" level="WEAK WARNING" enabled_by_default="true">
+      <option name="ignoredNames">
+        <list>
+          <option value="iter" />
+        </list>
+      </option>
+    </inspection_tool>
+    <inspection_tool class="PyShadowingNamesInspection" enabled="false" level="WEAK WARNING" enabled_by_default="false" />
+    <inspection_tool class="PyUnresolvedReferencesInspection" enabled="true" level="WARNING" enabled_by_default="true">
+      <option name="ignoredIdentifiers">
+        <list>
+          <option value="imutils" />
+          <option value="cv2" />
+          <option value="re" />
+          <option value="numpy" />
+          <option value="src.main.python.brailleProcessingLib.*" />
+          <option value="collections" />
+          <option value="src.main.python.test.*" />
         </list>
       </option>
     </inspection_tool>
Index: app/src/main/res/values/strings.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><resources>\r\n    <string name=\"app_name\">Braille2Text</string>\r\n    <string name=\"take_picture\">Take picture</string>\r\n</resources>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/src/main/res/values/strings.xml	(revision 48db88dd91de92680b233372650d3a88afb977cf)
+++ app/src/main/res/values/strings.xml	(date 1605236480301)
@@ -1,4 +1,6 @@
 <resources>
     <string name="app_name">Braille2Text</string>
     <string name="take_picture">Take picture</string>
+    <string name="title_item_list">Items</string>
+    <string name="title_item_detail">Item Detail</string>
 </resources>
\ No newline at end of file
diff --git .idea/shelf/Uncommitted_changes_before_rebase__Default_Changelist_.xml .idea/shelf/Uncommitted_changes_before_rebase__Default_Changelist_.xml
diff --git .idea/shelf/Uncommitted_changes_before_rebase__Default_Changelist_1.xml .idea/shelf/Uncommitted_changes_before_rebase__Default_Changelist_1.xml
diff --git .idea/shelf/Uncommitted_changes_before_rebase__Default_Changelist_2.xml .idea/shelf/Uncommitted_changes_before_rebase__Default_Changelist_2.xml
